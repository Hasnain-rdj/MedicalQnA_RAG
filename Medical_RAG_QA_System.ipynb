{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a585fc8e",
   "metadata": {},
   "source": [
    "# Medical RAG QA System using LangChain and Ollama\n",
    "\n",
    "## Project Overview\n",
    "This notebook implements a Retrieval-Augmented Generation (RAG) system for medical question answering.\n",
    "\n",
    "**Components:**\n",
    "- **Dataset**: Medical Transcriptions from Kaggle\n",
    "- **Embeddings**: HuggingFace Sentence Transformers (all-MiniLM-L6-v2)\n",
    "- **Vector Store**: FAISS (Facebook AI Similarity Search)\n",
    "- **LLM**: Llama 3.2 via Ollama\n",
    "- **Framework**: LangChain\n",
    "\n",
    "## How RAG Works:\n",
    "1. **Preprocessing**: Documents are split into smaller chunks\n",
    "2. **Embedding**: Chunks are converted to vector representations\n",
    "3. **Storage**: Vectors are stored in FAISS database for similarity search\n",
    "4. **Retrieval**: Relevant chunks are retrieved based on user queries\n",
    "5. **Generation**: LLM generates answers using the retrieved context\n",
    "\n",
    "## Setup Requirements:\n",
    "1. Download Medical Transcriptions dataset from [Kaggle](https://www.kaggle.com/datasets/tboyle10/medicaltranscriptions)\n",
    "2. Extract `mtsamples.csv` to the `data/` folder\n",
    "3. Install Ollama from [ollama.com](https://ollama.com)\n",
    "4. Install required Python libraries (see Step 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c2623",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd51521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying package installation...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hasnain\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
      "c:\\Users\\Hasnain\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Hasnain\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages verified:\n",
      "  - langchain\n",
      "  - langchain-ollama\n",
      "  - langchain-community\n",
      "  - langchain-text-splitters\n",
      "  - sentence-transformers\n",
      "  - faiss-cpu\n",
      "  - pandas, numpy\n"
     ]
    }
   ],
   "source": [
    "# Verify required packages are installed\n",
    "# To install: pip install langchain langchain-ollama langchain-community langchain-text-splitters sentence-transformers faiss-cpu pandas numpy\n",
    "\n",
    "print(\"Verifying package installation...\")\n",
    "try:\n",
    "    import langchain\n",
    "    import langchain_ollama\n",
    "    from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "    import langchain_text_splitters\n",
    "    import faiss\n",
    "    import pandas\n",
    "    import numpy\n",
    "    print(\"All required packages verified:\")\n",
    "    print(\"  - langchain\")\n",
    "    print(\"  - langchain-ollama\")\n",
    "    print(\"  - langchain-community\")\n",
    "    print(\"  - langchain-text-splitters\")\n",
    "    print(\"  - sentence-transformers\")\n",
    "    print(\"  - faiss-cpu\")\n",
    "    print(\"  - pandas, numpy\")\n",
    "except ImportError as e:\n",
    "    print(f\"Missing package: {e}\")\n",
    "    print(\"Install command: pip install langchain langchain-ollama langchain-community sentence-transformers faiss-cpu pandas numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb2662",
   "metadata": {},
   "source": [
    "## Note: Kernel Selection\n",
    "\n",
    "If you encounter import errors, ensure you're using Python 3.14:\n",
    "1. Click the kernel selector in the top-right corner\n",
    "2. Select Python 3.14 from the list\n",
    "3. Restart the kernel and re-run cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9eb069",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25801035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain components for RAG implementation\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Import RetrievalQA chain\n",
    "try:\n",
    "    from langchain.chains import RetrievalQA\n",
    "except ImportError:\n",
    "    from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67944459",
   "metadata": {},
   "source": [
    "## Step 3: Configure Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb87d075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Ollama installation...\n",
      "Model 'llama3.2' is available\n",
      "\n",
      "Model Configuration:\n",
      "  LLM: llama3.2\n",
      "  Embeddings: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# Configure model settings\n",
    "import subprocess\n",
    "\n",
    "# Model configuration\n",
    "LLM_MODEL = \"llama3.2\"  # Llama 3.2 model for text generation\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"  # Sentence transformer for embeddings\n",
    "\n",
    "# Verify Ollama installation and model availability\n",
    "print(\"Checking Ollama installation...\")\n",
    "try:\n",
    "    result = subprocess.run([\"ollama\", \"list\"], capture_output=True, text=True)\n",
    "    if LLM_MODEL in result.stdout:\n",
    "        print(f\"Model '{LLM_MODEL}' is available\")\n",
    "    else:\n",
    "        print(f\"Downloading '{LLM_MODEL}' model...\")\n",
    "        subprocess.run([\"ollama\", \"pull\", LLM_MODEL])\n",
    "        print(f\"Model '{LLM_MODEL}' downloaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: Ollama not found. Please install from https://ollama.com\")\n",
    "    print(f\"Details: {e}\")\n",
    "\n",
    "print(\"\\nModel Configuration:\")\n",
    "print(f\"  LLM: {LLM_MODEL}\")\n",
    "print(f\"  Embeddings: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752a89fc",
   "metadata": {},
   "source": [
    "## Step 4: Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbc5a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 4999 records\n",
      "Columns: ['Unnamed: 0', 'description', 'medical_specialty', 'sample_name', 'transcription', 'keywords']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0   A 23-year-old white female presents with comp...   \n",
       "1           1           Consult for laparoscopic gastric bypass.   \n",
       "2           2           Consult for laparoscopic gastric bypass.   \n",
       "3           3                             2-D M-Mode. Doppler.     \n",
       "4           4                                 2-D Echocardiogram   \n",
       "\n",
       "             medical_specialty                                sample_name  \\\n",
       "0         Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                   Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                   Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3   Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4   Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "\n",
       "                                       transcription  \\\n",
       "0  SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2  HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  allergy / immunology, allergic rhinitis, aller...  \n",
       "1  bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2  bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3  cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4  cardiovascular / pulmonary, 2-d, doppler, echo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load medical transcriptions dataset\n",
    "data_path = \"data/mtsamples.csv\"\n",
    "\n",
    "# Create data directory if needed\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "# Verify dataset exists\n",
    "if not Path(data_path).exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found at {Path(data_path).absolute()}\\n\"\n",
    "        f\"Download from: https://www.kaggle.com/datasets/tboyle10/medicaltranscriptions\"\n",
    "    )\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset loaded: {len(df)} records\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d087c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4999 entries, 0 to 4998\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Unnamed: 0         4999 non-null   int64 \n",
      " 1   description        4999 non-null   object\n",
      " 2   medical_specialty  4999 non-null   object\n",
      " 3   sample_name        4999 non-null   object\n",
      " 4   transcription      4966 non-null   object\n",
      " 5   keywords           3931 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 234.5+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "Unnamed: 0              0\n",
      "description             0\n",
      "medical_specialty       0\n",
      "sample_name             0\n",
      "transcription          33\n",
      "keywords             1068\n",
      "dtype: int64\n",
      "\n",
      "Top 10 Medical Specialties:\n",
      "medical_specialty\n",
      "Surgery                          1103\n",
      "Consult - History and Phy.        516\n",
      "Cardiovascular / Pulmonary        372\n",
      "Orthopedic                        355\n",
      "Radiology                         273\n",
      "General Medicine                  259\n",
      "Gastroenterology                  230\n",
      "Neurology                         223\n",
      "SOAP / Chart / Progress Notes     166\n",
      "Obstetrics / Gynecology           160\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore dataset structure\n",
    "print(\"Dataset Information:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nTop 10 Medical Specialties:\")\n",
    "print(df['medical_specialty'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfcc047",
   "metadata": {},
   "source": [
    "## Step 5: Data Preprocessing and Chunk Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f3676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned: 4943 valid records\n",
      "Processing 4943 records (100% of dataset)\n",
      "Estimated chunks: ~9886\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and preparation\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text by removing NaN and extra whitespace\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    return str(text).strip()\n",
    "\n",
    "# Fill missing values with empty strings\n",
    "df['transcription'] = df['transcription'].fillna('')\n",
    "df['description'] = df['description'].fillna('')\n",
    "df['medical_specialty'] = df['medical_specialty'].fillna('Unknown')\n",
    "df['keywords'] = df['keywords'].fillna('')\n",
    "\n",
    "# Remove records with very short transcriptions (less than 50 characters)\n",
    "df = df[df['transcription'].str.len() > 50].reset_index(drop=True)\n",
    "\n",
    "print(f\"Data cleaned: {len(df)} valid records\")\n",
    "\n",
    "# Use full dataset for processing\n",
    "DATASET_PERCENTAGE = 1.0\n",
    "sample_size = int(len(df) * DATASET_PERCENTAGE)\n",
    "df_subset = df.head(sample_size).copy()\n",
    "\n",
    "print(f\"Processing {len(df_subset)} records ({DATASET_PERCENTAGE*100:.0f}% of dataset)\")\n",
    "print(f\"Estimated chunks: ~{len(df_subset) * 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "620940d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4943 documents with metadata\n",
      "\n",
      "Sample document:\n",
      "Content preview: Description: A 23-year-old white female presents with complaint of allergies.\n",
      "\n",
      "Transcription: SUBJECTIVE:,  This 23-year-old white female presents with complaint of allergies.  She used to have allerg...\n",
      "Metadata: {'medical_specialty': 'Allergy / Immunology', 'keywords': 'allergy / immunology, allergic rhinitis, allergies, asthma, nasal sprays, rhinitis, nasal, erythematous, allegra, sprays, allergic,', 'sample_name': 'Allergic Rhinitis', 'source_id': 0}\n"
     ]
    }
   ],
   "source": [
    "# Create documents with metadata\n",
    "documents = []\n",
    "\n",
    "for idx, row in df_subset.iterrows():\n",
    "    # Combine description and transcription for richer context\n",
    "    content = f\"\"\"Description: {clean_text(row['description'])}\n",
    "    \n",
    "Transcription: {clean_text(row['transcription'])}\"\"\"\n",
    "    \n",
    "    # Create metadata for citation and filtering\n",
    "    metadata = {\n",
    "        'medical_specialty': clean_text(row['medical_specialty']),\n",
    "        'keywords': clean_text(row['keywords']),\n",
    "        'sample_name': clean_text(row.get('sample_name', '')),\n",
    "        'source_id': idx\n",
    "    }\n",
    "    \n",
    "    documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "print(f\"Created {len(documents)} documents with metadata\")\n",
    "print(f\"\\nSample document:\")\n",
    "print(f\"Content preview: {documents[0].page_content[:200]}...\")\n",
    "print(f\"Metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366e7807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents split into 25173 chunks\n",
      "\n",
      "Sample chunk:\n",
      "Content: Description: A 23-year-old white female presents with complaint of allergies....\n",
      "Metadata: {'medical_specialty': 'Allergy / Immunology', 'keywords': 'allergy / immunology, allergic rhinitis, allergies, asthma, nasal sprays, rhinitis, nasal, erythematous, allegra, sprays, allergic,', 'sample_name': 'Allergic Rhinitis', 'source_id': 0}\n"
     ]
    }
   ],
   "source": [
    "# Split documents into chunks for better retrieval\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # Size of each chunk\n",
    "    chunk_overlap=200,      # Overlap between chunks for context continuity\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Documents split into {len(chunks)} chunks\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(f\"Content: {chunks[0].page_content[:300]}...\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d14bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed chunks saved to: output\\preprocessed_chunks.pkl\n",
      "Total chunks: 25173\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed chunks\n",
    "output_dir = Path('output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "with open(output_dir / 'preprocessed_chunks.pkl', 'wb') as f:\n",
    "    pickle.dump(chunks, f)\n",
    "\n",
    "print(f\"Preprocessed chunks saved to: {output_dir / 'preprocessed_chunks.pkl'}\")\n",
    "print(f\"Total chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b90713",
   "metadata": {},
   "source": [
    "## Step 6: Create Embeddings and Vector Store (FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4f5f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding model...\n",
      "Note: First run will download model (~80MB)\n",
      "\n",
      "Embedding model initialized: all-MiniLM-L6-v2\n",
      "Embedding model initialized: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model\n",
    "print(\"Initializing embedding model...\")\n",
    "print(\"Note: First run will download model (~80MB)\\n\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL,\n",
    "    model_kwargs={'device': 'cpu'},  # Use 'cuda' for GPU acceleration\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(f\"Embedding model initialized: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffaf3097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FAISS vector store...\n",
      "Total chunks: 25173\n",
      "\n",
      "[Batch 1/252] Processing 100 chunks... Created\n",
      "[Batch 2/252] Processing 100 chunks... Created\n",
      "[Batch 2/252] Processing 100 chunks... Total: 200\n",
      "[Batch 3/252] Processing 100 chunks... Total: 200\n",
      "[Batch 3/252] Processing 100 chunks... Total: 300\n",
      "[Batch 4/252] Processing 100 chunks... Total: 300\n",
      "[Batch 4/252] Processing 100 chunks... Total: 400\n",
      "[Batch 5/252] Processing 100 chunks... Total: 400\n",
      "[Batch 5/252] Processing 100 chunks... Total: 500\n",
      "[Batch 6/252] Processing 100 chunks... Total: 500\n",
      "[Batch 6/252] Processing 100 chunks... Total: 600\n",
      "[Batch 7/252] Processing 100 chunks... Total: 600\n",
      "[Batch 7/252] Processing 100 chunks... Total: 700\n",
      "[Batch 8/252] Processing 100 chunks... Total: 700\n",
      "[Batch 8/252] Processing 100 chunks... Total: 800\n",
      "[Batch 9/252] Processing 100 chunks... Total: 800\n",
      "[Batch 9/252] Processing 100 chunks... Total: 900\n",
      "[Batch 10/252] Processing 100 chunks... Total: 900\n",
      "[Batch 10/252] Processing 100 chunks... Total: 1000\n",
      "[Batch 11/252] Processing 100 chunks... Total: 1000\n",
      "[Batch 11/252] Processing 100 chunks... Total: 1100\n",
      "[Batch 12/252] Processing 100 chunks... Total: 1100\n",
      "[Batch 12/252] Processing 100 chunks... Total: 1200\n",
      "[Batch 13/252] Processing 100 chunks... Total: 1200\n",
      "[Batch 13/252] Processing 100 chunks... Total: 1300\n",
      "[Batch 14/252] Processing 100 chunks... Total: 1300\n",
      "[Batch 14/252] Processing 100 chunks... Total: 1400\n",
      "[Batch 15/252] Processing 100 chunks... Total: 1400\n",
      "[Batch 15/252] Processing 100 chunks... Total: 1500\n",
      "[Batch 16/252] Processing 100 chunks... Total: 1500\n",
      "[Batch 16/252] Processing 100 chunks... Total: 1600\n",
      "[Batch 17/252] Processing 100 chunks... Total: 1600\n",
      "[Batch 17/252] Processing 100 chunks... Total: 1700\n",
      "[Batch 18/252] Processing 100 chunks... Total: 1700\n",
      "[Batch 18/252] Processing 100 chunks... Total: 1800\n",
      "[Batch 19/252] Processing 100 chunks... Total: 1800\n",
      "[Batch 19/252] Processing 100 chunks... Total: 1900\n",
      "[Batch 20/252] Processing 100 chunks... Total: 1900\n",
      "[Batch 20/252] Processing 100 chunks... Total: 2000\n",
      "[Batch 21/252] Processing 100 chunks... Total: 2000\n",
      "[Batch 21/252] Processing 100 chunks... Total: 2100\n",
      "[Batch 22/252] Processing 100 chunks... Total: 2100\n",
      "[Batch 22/252] Processing 100 chunks... Total: 2200\n",
      "[Batch 23/252] Processing 100 chunks... Total: 2200\n",
      "[Batch 23/252] Processing 100 chunks... Total: 2300\n",
      "[Batch 24/252] Processing 100 chunks... Total: 2300\n",
      "[Batch 24/252] Processing 100 chunks... Total: 2400\n",
      "[Batch 25/252] Processing 100 chunks... Total: 2400\n",
      "[Batch 25/252] Processing 100 chunks... Total: 2500\n",
      "[Batch 26/252] Processing 100 chunks... Total: 2500\n",
      "[Batch 26/252] Processing 100 chunks... Total: 2600\n",
      "[Batch 27/252] Processing 100 chunks... Total: 2600\n",
      "[Batch 27/252] Processing 100 chunks... Total: 2700\n",
      "[Batch 28/252] Processing 100 chunks... Total: 2700\n",
      "[Batch 28/252] Processing 100 chunks... Total: 2800\n",
      "[Batch 29/252] Processing 100 chunks... Total: 2800\n",
      "[Batch 29/252] Processing 100 chunks... Total: 2900\n",
      "[Batch 30/252] Processing 100 chunks... Total: 2900\n",
      "[Batch 30/252] Processing 100 chunks... Total: 3000\n",
      "[Batch 31/252] Processing 100 chunks... Total: 3000\n",
      "[Batch 31/252] Processing 100 chunks... Total: 3100\n",
      "[Batch 32/252] Processing 100 chunks... Total: 3100\n",
      "[Batch 32/252] Processing 100 chunks... Total: 3200\n",
      "[Batch 33/252] Processing 100 chunks... Total: 3200\n",
      "[Batch 33/252] Processing 100 chunks... Total: 3300\n",
      "[Batch 34/252] Processing 100 chunks... Total: 3300\n",
      "[Batch 34/252] Processing 100 chunks... Total: 3400\n",
      "[Batch 35/252] Processing 100 chunks... Total: 3400\n",
      "[Batch 35/252] Processing 100 chunks... Total: 3500\n",
      "[Batch 36/252] Processing 100 chunks... Total: 3500\n",
      "[Batch 36/252] Processing 100 chunks... Total: 3600\n",
      "[Batch 37/252] Processing 100 chunks... Total: 3600\n",
      "[Batch 37/252] Processing 100 chunks... Total: 3700\n",
      "[Batch 38/252] Processing 100 chunks... Total: 3700\n",
      "[Batch 38/252] Processing 100 chunks... Total: 3800\n",
      "[Batch 39/252] Processing 100 chunks... Total: 3800\n",
      "[Batch 39/252] Processing 100 chunks... Total: 3900\n",
      "[Batch 40/252] Processing 100 chunks... Total: 3900\n",
      "[Batch 40/252] Processing 100 chunks... Total: 4000\n",
      "[Batch 41/252] Processing 100 chunks... Total: 4000\n",
      "[Batch 41/252] Processing 100 chunks... Total: 4100\n",
      "[Batch 42/252] Processing 100 chunks... Total: 4100\n",
      "[Batch 42/252] Processing 100 chunks... Total: 4200\n",
      "[Batch 43/252] Processing 100 chunks... Total: 4200\n",
      "[Batch 43/252] Processing 100 chunks... Total: 4300\n",
      "[Batch 44/252] Processing 100 chunks... Total: 4300\n",
      "[Batch 44/252] Processing 100 chunks... Total: 4400\n",
      "[Batch 45/252] Processing 100 chunks... Total: 4400\n",
      "[Batch 45/252] Processing 100 chunks... Total: 4500\n",
      "[Batch 46/252] Processing 100 chunks... Total: 4500\n",
      "[Batch 46/252] Processing 100 chunks... Total: 4600\n",
      "[Batch 47/252] Processing 100 chunks... Total: 4600\n",
      "[Batch 47/252] Processing 100 chunks... Total: 4700\n",
      "[Batch 48/252] Processing 100 chunks... Total: 4700\n",
      "[Batch 48/252] Processing 100 chunks... Total: 4800\n",
      "[Batch 49/252] Processing 100 chunks... Total: 4800\n",
      "[Batch 49/252] Processing 100 chunks... Total: 4900\n",
      "[Batch 50/252] Processing 100 chunks... Total: 4900\n",
      "[Batch 50/252] Processing 100 chunks... Total: 5000\n",
      "[Batch 51/252] Processing 100 chunks... Total: 5000\n",
      "[Batch 51/252] Processing 100 chunks... Total: 5100\n",
      "[Batch 52/252] Processing 100 chunks... Total: 5100\n",
      "[Batch 52/252] Processing 100 chunks... Total: 5200\n",
      "[Batch 53/252] Processing 100 chunks... Total: 5200\n",
      "[Batch 53/252] Processing 100 chunks... Total: 5300\n",
      "[Batch 54/252] Processing 100 chunks... Total: 5300\n",
      "[Batch 54/252] Processing 100 chunks... Total: 5400\n",
      "[Batch 55/252] Processing 100 chunks... Total: 5400\n",
      "[Batch 55/252] Processing 100 chunks... Total: 5500\n",
      "[Batch 56/252] Processing 100 chunks... Total: 5500\n",
      "[Batch 56/252] Processing 100 chunks... Total: 5600\n",
      "[Batch 57/252] Processing 100 chunks... Total: 5600\n",
      "[Batch 57/252] Processing 100 chunks... Total: 5700\n",
      "[Batch 58/252] Processing 100 chunks... Total: 5700\n",
      "[Batch 58/252] Processing 100 chunks... Total: 5800\n",
      "[Batch 59/252] Processing 100 chunks... Total: 5800\n",
      "[Batch 59/252] Processing 100 chunks... Total: 5900\n",
      "[Batch 60/252] Processing 100 chunks... Total: 5900\n",
      "[Batch 60/252] Processing 100 chunks... Total: 6000\n",
      "[Batch 61/252] Processing 100 chunks... Total: 6000\n",
      "[Batch 61/252] Processing 100 chunks... Total: 6100\n",
      "[Batch 62/252] Processing 100 chunks... Total: 6100\n",
      "[Batch 62/252] Processing 100 chunks... Total: 6200\n",
      "[Batch 63/252] Processing 100 chunks... Total: 6200\n",
      "[Batch 63/252] Processing 100 chunks... Total: 6300\n",
      "[Batch 64/252] Processing 100 chunks... Total: 6300\n",
      "[Batch 64/252] Processing 100 chunks... Total: 6400\n",
      "[Batch 65/252] Processing 100 chunks... Total: 6400\n",
      "[Batch 65/252] Processing 100 chunks... Total: 6500\n",
      "[Batch 66/252] Processing 100 chunks... Total: 6500\n",
      "[Batch 66/252] Processing 100 chunks... Total: 6600\n",
      "[Batch 67/252] Processing 100 chunks... Total: 6600\n",
      "[Batch 67/252] Processing 100 chunks... Total: 6700\n",
      "[Batch 68/252] Processing 100 chunks... Total: 6700\n",
      "[Batch 68/252] Processing 100 chunks... Total: 6800\n",
      "[Batch 69/252] Processing 100 chunks... Total: 6800\n",
      "[Batch 69/252] Processing 100 chunks... Total: 6900\n",
      "[Batch 70/252] Processing 100 chunks... Total: 6900\n",
      "[Batch 70/252] Processing 100 chunks... Total: 7000\n",
      "[Batch 71/252] Processing 100 chunks... Total: 7000\n",
      "[Batch 71/252] Processing 100 chunks... Total: 7100\n",
      "[Batch 72/252] Processing 100 chunks... Total: 7100\n",
      "[Batch 72/252] Processing 100 chunks... Total: 7200\n",
      "[Batch 73/252] Processing 100 chunks... Total: 7200\n",
      "[Batch 73/252] Processing 100 chunks... Total: 7300\n",
      "[Batch 74/252] Processing 100 chunks... Total: 7300\n",
      "[Batch 74/252] Processing 100 chunks... Total: 7400\n",
      "[Batch 75/252] Processing 100 chunks... Total: 7400\n",
      "[Batch 75/252] Processing 100 chunks... Total: 7500\n",
      "[Batch 76/252] Processing 100 chunks... Total: 7500\n",
      "[Batch 76/252] Processing 100 chunks... Total: 7600\n",
      "[Batch 77/252] Processing 100 chunks... Total: 7600\n",
      "[Batch 77/252] Processing 100 chunks... Total: 7700\n",
      "[Batch 78/252] Processing 100 chunks... Total: 7700\n",
      "[Batch 78/252] Processing 100 chunks... Total: 7800\n",
      "[Batch 79/252] Processing 100 chunks... Total: 7800\n",
      "[Batch 79/252] Processing 100 chunks... Total: 7900\n",
      "[Batch 80/252] Processing 100 chunks... Total: 7900\n",
      "[Batch 80/252] Processing 100 chunks... Total: 8000\n",
      "[Batch 81/252] Processing 100 chunks... Total: 8000\n",
      "[Batch 81/252] Processing 100 chunks... Total: 8100\n",
      "[Batch 82/252] Processing 100 chunks... Total: 8100\n",
      "[Batch 82/252] Processing 100 chunks... Total: 8200\n",
      "[Batch 83/252] Processing 100 chunks... Total: 8200\n",
      "[Batch 83/252] Processing 100 chunks... Total: 8300\n",
      "[Batch 84/252] Processing 100 chunks... Total: 8300\n",
      "[Batch 84/252] Processing 100 chunks... Total: 8400\n",
      "[Batch 85/252] Processing 100 chunks... Total: 8400\n",
      "[Batch 85/252] Processing 100 chunks... Total: 8500\n",
      "[Batch 86/252] Processing 100 chunks... Total: 8500\n",
      "[Batch 86/252] Processing 100 chunks... Total: 8600\n",
      "[Batch 87/252] Processing 100 chunks... Total: 8600\n",
      "[Batch 87/252] Processing 100 chunks... Total: 8700\n",
      "[Batch 88/252] Processing 100 chunks... Total: 8700\n",
      "[Batch 88/252] Processing 100 chunks... Total: 8800\n",
      "[Batch 89/252] Processing 100 chunks... Total: 8800\n",
      "[Batch 89/252] Processing 100 chunks... Total: 8900\n",
      "[Batch 90/252] Processing 100 chunks... Total: 8900\n",
      "[Batch 90/252] Processing 100 chunks... Total: 9000\n",
      "[Batch 91/252] Processing 100 chunks... Total: 9000\n",
      "[Batch 91/252] Processing 100 chunks... Total: 9100\n",
      "[Batch 92/252] Processing 100 chunks... Total: 9100\n",
      "[Batch 92/252] Processing 100 chunks... Total: 9200\n",
      "[Batch 93/252] Processing 100 chunks... Total: 9200\n",
      "[Batch 93/252] Processing 100 chunks... Total: 9300\n",
      "[Batch 94/252] Processing 100 chunks... Total: 9300\n",
      "[Batch 94/252] Processing 100 chunks... Total: 9400\n",
      "[Batch 95/252] Processing 100 chunks... Total: 9400\n",
      "[Batch 95/252] Processing 100 chunks... Total: 9500\n",
      "[Batch 96/252] Processing 100 chunks... Total: 9500\n",
      "[Batch 96/252] Processing 100 chunks... Total: 9600\n",
      "[Batch 97/252] Processing 100 chunks... Total: 9600\n",
      "[Batch 97/252] Processing 100 chunks... Total: 9700\n",
      "[Batch 98/252] Processing 100 chunks... Total: 9700\n",
      "[Batch 98/252] Processing 100 chunks... Total: 9800\n",
      "[Batch 99/252] Processing 100 chunks... Total: 9800\n",
      "[Batch 99/252] Processing 100 chunks... Total: 9900\n",
      "[Batch 100/252] Processing 100 chunks... Total: 9900\n",
      "[Batch 100/252] Processing 100 chunks... Total: 10000\n",
      "[Batch 101/252] Processing 100 chunks... Total: 10000\n",
      "[Batch 101/252] Processing 100 chunks... Total: 10100\n",
      "[Batch 102/252] Processing 100 chunks... Total: 10100\n",
      "[Batch 102/252] Processing 100 chunks... Total: 10200\n",
      "[Batch 103/252] Processing 100 chunks... Total: 10200\n",
      "[Batch 103/252] Processing 100 chunks... Total: 10300\n",
      "[Batch 104/252] Processing 100 chunks... Total: 10300\n",
      "[Batch 104/252] Processing 100 chunks... Total: 10400\n",
      "[Batch 105/252] Processing 100 chunks... Total: 10400\n",
      "[Batch 105/252] Processing 100 chunks... Total: 10500\n",
      "[Batch 106/252] Processing 100 chunks... Total: 10500\n",
      "[Batch 106/252] Processing 100 chunks... Total: 10600\n",
      "[Batch 107/252] Processing 100 chunks... Total: 10600\n",
      "[Batch 107/252] Processing 100 chunks... Total: 10700\n",
      "[Batch 108/252] Processing 100 chunks... Total: 10700\n",
      "[Batch 108/252] Processing 100 chunks... Total: 10800\n",
      "[Batch 109/252] Processing 100 chunks... Total: 10800\n",
      "[Batch 109/252] Processing 100 chunks... Total: 10900\n",
      "[Batch 110/252] Processing 100 chunks... Total: 10900\n",
      "[Batch 110/252] Processing 100 chunks... Total: 11000\n",
      "[Batch 111/252] Processing 100 chunks... Total: 11000\n",
      "[Batch 111/252] Processing 100 chunks... Total: 11100\n",
      "[Batch 112/252] Processing 100 chunks... Total: 11100\n",
      "[Batch 112/252] Processing 100 chunks... Total: 11200\n",
      "[Batch 113/252] Processing 100 chunks... Total: 11200\n",
      "[Batch 113/252] Processing 100 chunks... Total: 11300\n",
      "[Batch 114/252] Processing 100 chunks... Total: 11300\n",
      "[Batch 114/252] Processing 100 chunks... Total: 11400\n",
      "[Batch 115/252] Processing 100 chunks... Total: 11400\n",
      "[Batch 115/252] Processing 100 chunks... Total: 11500\n",
      "[Batch 116/252] Processing 100 chunks... Total: 11500\n",
      "[Batch 116/252] Processing 100 chunks... Total: 11600\n",
      "[Batch 117/252] Processing 100 chunks... Total: 11600\n",
      "[Batch 117/252] Processing 100 chunks... Total: 11700\n",
      "[Batch 118/252] Processing 100 chunks... Total: 11700\n",
      "[Batch 118/252] Processing 100 chunks... Total: 11800\n",
      "[Batch 119/252] Processing 100 chunks... Total: 11800\n",
      "[Batch 119/252] Processing 100 chunks... Total: 11900\n",
      "[Batch 120/252] Processing 100 chunks... Total: 11900\n",
      "[Batch 120/252] Processing 100 chunks... Total: 12000\n",
      "[Batch 121/252] Processing 100 chunks... Total: 12000\n",
      "[Batch 121/252] Processing 100 chunks... Total: 12100\n",
      "[Batch 122/252] Processing 100 chunks... Total: 12100\n",
      "[Batch 122/252] Processing 100 chunks... Total: 12200\n",
      "[Batch 123/252] Processing 100 chunks... Total: 12200\n",
      "[Batch 123/252] Processing 100 chunks... Total: 12300\n",
      "[Batch 124/252] Processing 100 chunks... Total: 12300\n",
      "[Batch 124/252] Processing 100 chunks... Total: 12400\n",
      "[Batch 125/252] Processing 100 chunks... Total: 12400\n",
      "[Batch 125/252] Processing 100 chunks... Total: 12500\n",
      "[Batch 126/252] Processing 100 chunks... Total: 12500\n",
      "[Batch 126/252] Processing 100 chunks... Total: 12600\n",
      "[Batch 127/252] Processing 100 chunks... Total: 12600\n",
      "[Batch 127/252] Processing 100 chunks... Total: 12700\n",
      "[Batch 128/252] Processing 100 chunks... Total: 12700\n",
      "[Batch 128/252] Processing 100 chunks... Total: 12800\n",
      "[Batch 129/252] Processing 100 chunks... Total: 12800\n",
      "[Batch 129/252] Processing 100 chunks... Total: 12900\n",
      "[Batch 130/252] Processing 100 chunks... Total: 12900\n",
      "[Batch 130/252] Processing 100 chunks... Total: 13000\n",
      "[Batch 131/252] Processing 100 chunks... Total: 13000\n",
      "[Batch 131/252] Processing 100 chunks... Total: 13100\n",
      "[Batch 132/252] Processing 100 chunks... Total: 13100\n",
      "[Batch 132/252] Processing 100 chunks... Total: 13200\n",
      "[Batch 133/252] Processing 100 chunks... Total: 13200\n",
      "[Batch 133/252] Processing 100 chunks... Total: 13300\n",
      "[Batch 134/252] Processing 100 chunks... Total: 13300\n",
      "[Batch 134/252] Processing 100 chunks... Total: 13400\n",
      "[Batch 135/252] Processing 100 chunks... Total: 13400\n",
      "[Batch 135/252] Processing 100 chunks... Total: 13500\n",
      "[Batch 136/252] Processing 100 chunks... Total: 13500\n",
      "[Batch 136/252] Processing 100 chunks... Total: 13600\n",
      "[Batch 137/252] Processing 100 chunks... Total: 13600\n",
      "[Batch 137/252] Processing 100 chunks... Total: 13700\n",
      "[Batch 138/252] Processing 100 chunks... Total: 13700\n",
      "[Batch 138/252] Processing 100 chunks... Total: 13800\n",
      "[Batch 139/252] Processing 100 chunks... Total: 13800\n",
      "[Batch 139/252] Processing 100 chunks... Total: 13900\n",
      "[Batch 140/252] Processing 100 chunks... Total: 13900\n",
      "[Batch 140/252] Processing 100 chunks... Total: 14000\n",
      "[Batch 141/252] Processing 100 chunks... Total: 14000\n",
      "[Batch 141/252] Processing 100 chunks... Total: 14100\n",
      "[Batch 142/252] Processing 100 chunks... Total: 14100\n",
      "[Batch 142/252] Processing 100 chunks... Total: 14200\n",
      "[Batch 143/252] Processing 100 chunks... Total: 14200\n",
      "[Batch 143/252] Processing 100 chunks... Total: 14300\n",
      "[Batch 144/252] Processing 100 chunks... Total: 14300\n",
      "[Batch 144/252] Processing 100 chunks... Total: 14400\n",
      "[Batch 145/252] Processing 100 chunks... Total: 14400\n",
      "[Batch 145/252] Processing 100 chunks... Total: 14500\n",
      "[Batch 146/252] Processing 100 chunks... Total: 14500\n",
      "[Batch 146/252] Processing 100 chunks... Total: 14600\n",
      "[Batch 147/252] Processing 100 chunks... Total: 14600\n",
      "[Batch 147/252] Processing 100 chunks... Total: 14700\n",
      "[Batch 148/252] Processing 100 chunks... Total: 14700\n",
      "[Batch 148/252] Processing 100 chunks... Total: 14800\n",
      "[Batch 149/252] Processing 100 chunks... Total: 14800\n",
      "[Batch 149/252] Processing 100 chunks... Total: 14900\n",
      "[Batch 150/252] Processing 100 chunks... Total: 14900\n",
      "[Batch 150/252] Processing 100 chunks... Total: 15000\n",
      "[Batch 151/252] Processing 100 chunks... Total: 15000\n",
      "[Batch 151/252] Processing 100 chunks... Total: 15100\n",
      "[Batch 152/252] Processing 100 chunks... Total: 15100\n",
      "[Batch 152/252] Processing 100 chunks... Total: 15200\n",
      "[Batch 153/252] Processing 100 chunks... Total: 15200\n",
      "[Batch 153/252] Processing 100 chunks... Total: 15300\n",
      "[Batch 154/252] Processing 100 chunks... Total: 15300\n",
      "[Batch 154/252] Processing 100 chunks... Total: 15400\n",
      "[Batch 155/252] Processing 100 chunks... Total: 15400\n",
      "[Batch 155/252] Processing 100 chunks... Total: 15500\n",
      "[Batch 156/252] Processing 100 chunks... Total: 15500\n",
      "[Batch 156/252] Processing 100 chunks... Total: 15600\n",
      "[Batch 157/252] Processing 100 chunks... Total: 15600\n",
      "[Batch 157/252] Processing 100 chunks... Total: 15700\n",
      "[Batch 158/252] Processing 100 chunks... Total: 15700\n",
      "[Batch 158/252] Processing 100 chunks... Total: 15800\n",
      "[Batch 159/252] Processing 100 chunks... Total: 15800\n",
      "[Batch 159/252] Processing 100 chunks... Total: 15900\n",
      "[Batch 160/252] Processing 100 chunks... Total: 15900\n",
      "[Batch 160/252] Processing 100 chunks... Total: 16000\n",
      "[Batch 161/252] Processing 100 chunks... Total: 16000\n",
      "[Batch 161/252] Processing 100 chunks... Total: 16100\n",
      "[Batch 162/252] Processing 100 chunks... Total: 16100\n",
      "[Batch 162/252] Processing 100 chunks... Total: 16200\n",
      "[Batch 163/252] Processing 100 chunks... Total: 16200\n",
      "[Batch 163/252] Processing 100 chunks... Total: 16300\n",
      "[Batch 164/252] Processing 100 chunks... Total: 16300\n",
      "[Batch 164/252] Processing 100 chunks... Total: 16400\n",
      "[Batch 165/252] Processing 100 chunks... Total: 16400\n",
      "[Batch 165/252] Processing 100 chunks... Total: 16500\n",
      "[Batch 166/252] Processing 100 chunks... Total: 16500\n",
      "[Batch 166/252] Processing 100 chunks... Total: 16600\n",
      "[Batch 167/252] Processing 100 chunks... Total: 16600\n",
      "[Batch 167/252] Processing 100 chunks... Total: 16700\n",
      "[Batch 168/252] Processing 100 chunks... Total: 16700\n",
      "[Batch 168/252] Processing 100 chunks... Total: 16800\n",
      "[Batch 169/252] Processing 100 chunks... Total: 16800\n",
      "[Batch 169/252] Processing 100 chunks... Total: 16900\n",
      "[Batch 170/252] Processing 100 chunks... Total: 16900\n",
      "[Batch 170/252] Processing 100 chunks... Total: 17000\n",
      "[Batch 171/252] Processing 100 chunks... Total: 17000\n",
      "[Batch 171/252] Processing 100 chunks... Total: 17100\n",
      "[Batch 172/252] Processing 100 chunks... Total: 17100\n",
      "[Batch 172/252] Processing 100 chunks... Total: 17200\n",
      "[Batch 173/252] Processing 100 chunks... Total: 17200\n",
      "[Batch 173/252] Processing 100 chunks... Total: 17300\n",
      "[Batch 174/252] Processing 100 chunks... Total: 17300\n",
      "[Batch 174/252] Processing 100 chunks... Total: 17400\n",
      "[Batch 175/252] Processing 100 chunks... Total: 17400\n",
      "[Batch 175/252] Processing 100 chunks... Total: 17500\n",
      "[Batch 176/252] Processing 100 chunks... Total: 17500\n",
      "[Batch 176/252] Processing 100 chunks... Total: 17600\n",
      "[Batch 177/252] Processing 100 chunks... Total: 17600\n",
      "[Batch 177/252] Processing 100 chunks... Total: 17700\n",
      "[Batch 178/252] Processing 100 chunks... Total: 17700\n",
      "[Batch 178/252] Processing 100 chunks... Total: 17800\n",
      "[Batch 179/252] Processing 100 chunks... Total: 17800\n",
      "[Batch 179/252] Processing 100 chunks... Total: 17900\n",
      "[Batch 180/252] Processing 100 chunks... Total: 17900\n",
      "[Batch 180/252] Processing 100 chunks... Total: 18000\n",
      "[Batch 181/252] Processing 100 chunks... Total: 18000\n",
      "[Batch 181/252] Processing 100 chunks... Total: 18100\n",
      "[Batch 182/252] Processing 100 chunks... Total: 18100\n",
      "[Batch 182/252] Processing 100 chunks... Total: 18200\n",
      "[Batch 183/252] Processing 100 chunks... Total: 18200\n",
      "[Batch 183/252] Processing 100 chunks... Total: 18300\n",
      "[Batch 184/252] Processing 100 chunks... Total: 18300\n",
      "[Batch 184/252] Processing 100 chunks... Total: 18400\n",
      "[Batch 185/252] Processing 100 chunks... Total: 18400\n",
      "[Batch 185/252] Processing 100 chunks... Total: 18500\n",
      "[Batch 186/252] Processing 100 chunks... Total: 18500\n",
      "[Batch 186/252] Processing 100 chunks... Total: 18600\n",
      "[Batch 187/252] Processing 100 chunks... Total: 18600\n",
      "[Batch 187/252] Processing 100 chunks... Total: 18700\n",
      "[Batch 188/252] Processing 100 chunks... Total: 18700\n",
      "[Batch 188/252] Processing 100 chunks... Total: 18800\n",
      "[Batch 189/252] Processing 100 chunks... Total: 18800\n",
      "[Batch 189/252] Processing 100 chunks... Total: 18900\n",
      "[Batch 190/252] Processing 100 chunks... Total: 18900\n",
      "[Batch 190/252] Processing 100 chunks... Total: 19000\n",
      "[Batch 191/252] Processing 100 chunks... Total: 19000\n",
      "[Batch 191/252] Processing 100 chunks... Total: 19100\n",
      "[Batch 192/252] Processing 100 chunks... Total: 19100\n",
      "[Batch 192/252] Processing 100 chunks... Total: 19200\n",
      "[Batch 193/252] Processing 100 chunks... Total: 19200\n",
      "[Batch 193/252] Processing 100 chunks... Total: 19300\n",
      "[Batch 194/252] Processing 100 chunks... Total: 19300\n",
      "[Batch 194/252] Processing 100 chunks... Total: 19400\n",
      "[Batch 195/252] Processing 100 chunks... Total: 19400\n",
      "[Batch 195/252] Processing 100 chunks... Total: 19500\n",
      "[Batch 196/252] Processing 100 chunks... Total: 19500\n",
      "[Batch 196/252] Processing 100 chunks... Total: 19600\n",
      "[Batch 197/252] Processing 100 chunks... Total: 19600\n",
      "[Batch 197/252] Processing 100 chunks... Total: 19700\n",
      "[Batch 198/252] Processing 100 chunks... Total: 19700\n",
      "[Batch 198/252] Processing 100 chunks... Total: 19800\n",
      "[Batch 199/252] Processing 100 chunks... Total: 19800\n",
      "[Batch 199/252] Processing 100 chunks... Total: 19900\n",
      "[Batch 200/252] Processing 100 chunks... Total: 19900\n",
      "[Batch 200/252] Processing 100 chunks... Total: 20000\n",
      "[Batch 201/252] Processing 100 chunks... Total: 20000\n",
      "[Batch 201/252] Processing 100 chunks... Total: 20100\n",
      "[Batch 202/252] Processing 100 chunks... Total: 20100\n",
      "[Batch 202/252] Processing 100 chunks... Total: 20200\n",
      "[Batch 203/252] Processing 100 chunks... Total: 20200\n",
      "[Batch 203/252] Processing 100 chunks... Total: 20300\n",
      "[Batch 204/252] Processing 100 chunks... Total: 20300\n",
      "[Batch 204/252] Processing 100 chunks... Total: 20400\n",
      "[Batch 205/252] Processing 100 chunks... Total: 20400\n",
      "[Batch 205/252] Processing 100 chunks... Total: 20500\n",
      "[Batch 206/252] Processing 100 chunks... Total: 20500\n",
      "[Batch 206/252] Processing 100 chunks... Total: 20600\n",
      "[Batch 207/252] Processing 100 chunks... Total: 20600\n",
      "[Batch 207/252] Processing 100 chunks... Total: 20700\n",
      "[Batch 208/252] Processing 100 chunks... Total: 20700\n",
      "[Batch 208/252] Processing 100 chunks... Total: 20800\n",
      "[Batch 209/252] Processing 100 chunks... Total: 20800\n",
      "[Batch 209/252] Processing 100 chunks... Total: 20900\n",
      "[Batch 210/252] Processing 100 chunks... Total: 20900\n",
      "[Batch 210/252] Processing 100 chunks... Total: 21000\n",
      "[Batch 211/252] Processing 100 chunks... Total: 21000\n",
      "[Batch 211/252] Processing 100 chunks... Total: 21100\n",
      "[Batch 212/252] Processing 100 chunks... Total: 21100\n",
      "[Batch 212/252] Processing 100 chunks... Total: 21200\n",
      "[Batch 213/252] Processing 100 chunks... Total: 21200\n",
      "[Batch 213/252] Processing 100 chunks... Total: 21300\n",
      "[Batch 214/252] Processing 100 chunks... Total: 21300\n",
      "[Batch 214/252] Processing 100 chunks... Total: 21400\n",
      "[Batch 215/252] Processing 100 chunks... Total: 21400\n",
      "[Batch 215/252] Processing 100 chunks... Total: 21500\n",
      "[Batch 216/252] Processing 100 chunks... Total: 21500\n",
      "[Batch 216/252] Processing 100 chunks... Total: 21600\n",
      "[Batch 217/252] Processing 100 chunks... Total: 21600\n",
      "[Batch 217/252] Processing 100 chunks... Total: 21700\n",
      "[Batch 218/252] Processing 100 chunks... Total: 21700\n",
      "[Batch 218/252] Processing 100 chunks... Total: 21800\n",
      "[Batch 219/252] Processing 100 chunks... Total: 21800\n",
      "[Batch 219/252] Processing 100 chunks... Total: 21900\n",
      "[Batch 220/252] Processing 100 chunks... Total: 21900\n",
      "[Batch 220/252] Processing 100 chunks... Total: 22000\n",
      "[Batch 221/252] Processing 100 chunks... Total: 22000\n",
      "[Batch 221/252] Processing 100 chunks... Total: 22100\n",
      "[Batch 222/252] Processing 100 chunks... Total: 22100\n",
      "[Batch 222/252] Processing 100 chunks... Total: 22200\n",
      "[Batch 223/252] Processing 100 chunks... Total: 22200\n",
      "[Batch 223/252] Processing 100 chunks... Total: 22300\n",
      "[Batch 224/252] Processing 100 chunks... Total: 22300\n",
      "[Batch 224/252] Processing 100 chunks... Total: 22400\n",
      "[Batch 225/252] Processing 100 chunks... Total: 22400\n",
      "[Batch 225/252] Processing 100 chunks... Total: 22500\n",
      "[Batch 226/252] Processing 100 chunks... Total: 22500\n",
      "[Batch 226/252] Processing 100 chunks... Total: 22600\n",
      "[Batch 227/252] Processing 100 chunks... Total: 22600\n",
      "[Batch 227/252] Processing 100 chunks... Total: 22700\n",
      "[Batch 228/252] Processing 100 chunks... Total: 22700\n",
      "[Batch 228/252] Processing 100 chunks... Total: 22800\n",
      "[Batch 229/252] Processing 100 chunks... Total: 22800\n",
      "[Batch 229/252] Processing 100 chunks... Total: 22900\n",
      "[Batch 230/252] Processing 100 chunks... Total: 22900\n",
      "[Batch 230/252] Processing 100 chunks... Total: 23000\n",
      "[Batch 231/252] Processing 100 chunks... Total: 23000\n",
      "[Batch 231/252] Processing 100 chunks... Total: 23100\n",
      "[Batch 232/252] Processing 100 chunks... Total: 23100\n",
      "[Batch 232/252] Processing 100 chunks... Total: 23200\n",
      "[Batch 233/252] Processing 100 chunks... Total: 23200\n",
      "[Batch 233/252] Processing 100 chunks... Total: 23300\n",
      "[Batch 234/252] Processing 100 chunks... Total: 23300\n",
      "[Batch 234/252] Processing 100 chunks... Total: 23400\n",
      "[Batch 235/252] Processing 100 chunks... Total: 23400\n",
      "[Batch 235/252] Processing 100 chunks... Total: 23500\n",
      "[Batch 236/252] Processing 100 chunks... Total: 23500\n",
      "[Batch 236/252] Processing 100 chunks... Total: 23600\n",
      "[Batch 237/252] Processing 100 chunks... Total: 23600\n",
      "[Batch 237/252] Processing 100 chunks... Total: 23700\n",
      "[Batch 238/252] Processing 100 chunks... Total: 23700\n",
      "[Batch 238/252] Processing 100 chunks... Total: 23800\n",
      "[Batch 239/252] Processing 100 chunks... Total: 23800\n",
      "[Batch 239/252] Processing 100 chunks... Total: 23900\n",
      "[Batch 240/252] Processing 100 chunks... Total: 23900\n",
      "[Batch 240/252] Processing 100 chunks... Total: 24000\n",
      "[Batch 241/252] Processing 100 chunks... Total: 24000\n",
      "[Batch 241/252] Processing 100 chunks... Total: 24100\n",
      "[Batch 242/252] Processing 100 chunks... Total: 24100\n",
      "[Batch 242/252] Processing 100 chunks... Total: 24200\n",
      "[Batch 243/252] Processing 100 chunks... Total: 24200\n",
      "[Batch 243/252] Processing 100 chunks... Total: 24300\n",
      "[Batch 244/252] Processing 100 chunks... Total: 24300\n",
      "[Batch 244/252] Processing 100 chunks... Total: 24400\n",
      "[Batch 245/252] Processing 100 chunks... Total: 24400\n",
      "[Batch 245/252] Processing 100 chunks... Total: 24500\n",
      "[Batch 246/252] Processing 100 chunks... Total: 24500\n",
      "[Batch 246/252] Processing 100 chunks... Total: 24600\n",
      "[Batch 247/252] Processing 100 chunks... Total: 24600\n",
      "[Batch 247/252] Processing 100 chunks... Total: 24700\n",
      "[Batch 248/252] Processing 100 chunks... Total: 24700\n",
      "[Batch 248/252] Processing 100 chunks... Total: 24800\n",
      "[Batch 249/252] Processing 100 chunks... Total: 24800\n",
      "[Batch 249/252] Processing 100 chunks... Total: 24900\n",
      "[Batch 250/252] Processing 100 chunks... Total: 24900\n",
      "[Batch 250/252] Processing 100 chunks... Total: 25000\n",
      "[Batch 251/252] Processing 100 chunks... Total: 25000\n",
      "[Batch 251/252] Processing 100 chunks... Total: 25100\n",
      "[Batch 252/252] Processing 73 chunks... Total: 25100\n",
      "[Batch 252/252] Processing 73 chunks... Total: 25173\n",
      "\n",
      "Vector store created successfully\n",
      "Total vectors: 25173\n",
      "Time taken: 741.9s (33.9 chunks/s)\n",
      "Total: 25173\n",
      "\n",
      "Vector store created successfully\n",
      "Total vectors: 25173\n",
      "Time taken: 741.9s (33.9 chunks/s)\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS vector store\n",
    "import time\n",
    "\n",
    "print(\"Creating FAISS vector store...\")\n",
    "print(f\"Total chunks: {len(chunks)}\\n\")\n",
    "\n",
    "try:\n",
    "    batch_size = 100\n",
    "    vectorstore = None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process chunks in batches for progress tracking\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        batch_num = i//batch_size + 1\n",
    "        total_batches = (len(chunks) + batch_size - 1) // batch_size\n",
    "        \n",
    "        print(f\"[Batch {batch_num}/{total_batches}] Processing {len(batch)} chunks...\", end=\" \")\n",
    "        \n",
    "        if vectorstore is None:\n",
    "            vectorstore = FAISS.from_documents(documents=batch, embedding=embeddings)\n",
    "            print(f\"Created\")\n",
    "        else:\n",
    "            vectorstore.add_documents(batch)\n",
    "            print(f\"Total: {vectorstore.index.ntotal}\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nVector store created successfully\")\n",
    "    print(f\"Total vectors: {vectorstore.index.ntotal}\")\n",
    "    print(f\"Time taken: {elapsed:.1f}s ({len(chunks)/elapsed:.1f} chunks/s)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {str(e)[:300]}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eb345ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vector store saved to: output\\faiss_medical_index\n"
     ]
    }
   ],
   "source": [
    "# Save FAISS vector store\n",
    "vectorstore.save_local(str(output_dir / 'faiss_medical_index'))\n",
    "\n",
    "print(f\"FAISS vector store saved to: {output_dir / 'faiss_medical_index'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6ea898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Query: 'What are the symptoms of diabetes?'\n",
      "\n",
      "Top 3 Retrieved Chunks:\n",
      "==================================================\n",
      "\n",
      "[Chunk 1]\n",
      "Specialty: General Medicine\n",
      "Content: .  As far as diabetes father and grandfather had type II diabetes.  Son has type I diabetes and is struggling with that at the moment.,REVIEW OF SYSTEMS:,General:  No fever, chills, or night sweats.  ...\n",
      "--------------------------------------------------\n",
      "\n",
      "[Chunk 2]\n",
      "Specialty: Consult - History and Phy.\n",
      "Content: .  As far as diabetes father and grandfather had type II diabetes.  Son has type I diabetes and is struggling with that at the moment.,REVIEW OF SYSTEMS:,General:  No fever, chills, or night sweats.  ...\n",
      "--------------------------------------------------\n",
      "\n",
      "[Chunk 3]\n",
      "Specialty: SOAP / Chart / Progress Notes\n",
      "Content: Transcription: SUBJECTIVE:,  The patient is a 66-year-old female who presents to the clinic today for a five-month recheck on her type II diabetes mellitus, as well as hypertension.  While here she ha...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test vector store with a sample query\n",
    "test_query = \"What are the symptoms of diabetes?\"\n",
    "retrieved_docs = vectorstore.similarity_search(test_query, k=3)\n",
    "\n",
    "print(f\"Test Query: '{test_query}'\")\n",
    "print(f\"\\nTop 3 Retrieved Chunks:\\n\" + \"=\"*50)\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"\\n[Chunk {i}]\")\n",
    "    print(f\"Specialty: {doc.metadata.get('medical_specialty', 'Unknown')}\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3929092",
   "metadata": {},
   "source": [
    "## Step 7: Build RAG Pipeline with Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c29bd570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized: llama3.2\n",
      "Temperature: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Initialize language model\n",
    "llm = ChatOllama(\n",
    "    model=LLM_MODEL,\n",
    "    temperature=0.3,  # Lower temperature for more factual responses\n",
    ")\n",
    "\n",
    "print(f\"LLM initialized: {LLM_MODEL}\")\n",
    "print(f\"Temperature: 0.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0e4e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom prompt template created\n"
     ]
    }
   ],
   "source": [
    "# Create custom prompt template for medical QA\n",
    "prompt_template = \"\"\"You are a medical assistant that provides accurate, evidence-based answers using the provided context from medical transcriptions.\n",
    "\n",
    "Instructions:\n",
    "- Answer based ONLY on the provided context\n",
    "- If the context doesn't contain enough information, say \"I don't have enough information in the provided context to answer this question accurately.\"\n",
    "- Include the medical specialty when relevant\n",
    "- Be clear and concise\n",
    "- Always prioritize patient safety in your responses\n",
    "\n",
    "Context from medical records:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"Custom prompt template created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6e7e64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG pipeline created\n",
      "Configuration:\n",
      "  - Retrieval: Top 4 similar chunks\n",
      "  - LLM: llama3.2\n",
      "  - Chain: Stuff\n"
     ]
    }
   ],
   "source": [
    "# Create RAG chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 4}  # Retrieve top 4 most relevant chunks\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "print(\"RAG pipeline created\")\n",
    "print(\"Configuration:\")\n",
    "print(f\"  - Retrieval: Top 4 similar chunks\")\n",
    "print(f\"  - LLM: {LLM_MODEL}\")\n",
    "print(f\"  - Chain: Stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57830e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG configuration saved to: output\\rag_config.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save RAG pipeline components\n",
    "rag_components = {\n",
    "    'vectorstore_path': str(output_dir / 'faiss_medical_index'),\n",
    "    'model_name': LLM_MODEL,\n",
    "    'embedding_model': EMBEDDING_MODEL,\n",
    "    'chunk_size': 1000,\n",
    "    'chunk_overlap': 200,\n",
    "    'retriever_k': 4,\n",
    "    'temperature': 0.3\n",
    "}\n",
    "\n",
    "with open(output_dir / 'rag_config.pkl', 'wb') as f:\n",
    "    pickle.dump(rag_components, f)\n",
    "\n",
    "print(f\"RAG configuration saved to: {output_dir / 'rag_config.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad2671",
   "metadata": {},
   "source": [
    "## Step 8: Test RAG Pipeline with Sample Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cad38b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_medical_question(question):\n",
    "    \"\"\"Query the RAG system and display answer with sources\"\"\"\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nAnswer:\\n{result['result']}\")\n",
    "    print(f\"\\nSources ({len(result['source_documents'])} documents):\")\n",
    "    \n",
    "    for i, doc in enumerate(result['source_documents'], 1):\n",
    "        print(f\"\\n[{i}] {doc.metadata.get('medical_specialty', 'Unknown')}\")\n",
    "        print(f\"    Keywords: {doc.metadata.get('keywords', 'N/A')[:100]}\")\n",
    "        print(f\"    Preview: {doc.page_content[:150]}...\")\n",
    "    \n",
    "    print(f\"{'='*70}\\n\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e861e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAG pipeline...\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Question: What are common symptoms of coronary artery disease?\n",
      "======================================================================\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, common symptoms of coronary artery disease (CAD) include:\n",
      "\n",
      "* Chest pain or discomfort, often described as a pressure-type dull ache or heavy pressure\n",
      "* Pain that may radiate to the jaw, left arm, teeth, and/or outer ear\n",
      "* Possibly numbness, tingling, or pain in the arm, shoulder, elbow, or chest\n",
      "* Sudden difficulty breathing\n",
      "* Pain located between the shoulder blades\n",
      "\n",
      "These symptoms are often described as angina pectoris.\n",
      "\n",
      "Sources (4 documents):\n",
      "\n",
      "[1] Cardiovascular / Pulmonary\n",
      "    Keywords: cardiovascular / pulmonary, lack of oxygen, heart valve, arrhythmias, blood pressure, heart, tightne\n",
      "    Preview: . not enough oxygen to the heart muscles).  Other causes could be due to a hyperactive thyroid disorder or anemia.  People more likely to have angina ...\n",
      "\n",
      "[2] General Medicine\n",
      "    Keywords: \n",
      "    Preview: Transcription: REASON FOR CONSULTATION:,  Chest pain.,HISTORY OF PRESENT ILLNESS: , The patient is a 37-year-old gentleman admitted through emergency ...\n",
      "\n",
      "[3] Consult - History and Phy.\n",
      "    Keywords: \n",
      "    Preview: Transcription: REASON FOR CONSULTATION:,  Chest pain.,HISTORY OF PRESENT ILLNESS: , The patient is a 37-year-old gentleman admitted through emergency ...\n",
      "\n",
      "[4] Consult - History and Phy.\n",
      "    Keywords: \n",
      "    Preview: Transcription: CHIEF COMPLAINT (1/1):, This 62 year old female presents today for evaluation of angina.,Associated signs and symptoms: Associated sign...\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Question: What are common symptoms of coronary artery disease?\n",
      "======================================================================\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, common symptoms of coronary artery disease (CAD) include:\n",
      "\n",
      "* Chest pain or discomfort, often described as a pressure-type dull ache or heavy pressure\n",
      "* Pain that may radiate to the jaw, left arm, teeth, and/or outer ear\n",
      "* Possibly numbness, tingling, or pain in the arm, shoulder, elbow, or chest\n",
      "* Sudden difficulty breathing\n",
      "* Pain located between the shoulder blades\n",
      "\n",
      "These symptoms are often described as angina pectoris.\n",
      "\n",
      "Sources (4 documents):\n",
      "\n",
      "[1] Cardiovascular / Pulmonary\n",
      "    Keywords: cardiovascular / pulmonary, lack of oxygen, heart valve, arrhythmias, blood pressure, heart, tightne\n",
      "    Preview: . not enough oxygen to the heart muscles).  Other causes could be due to a hyperactive thyroid disorder or anemia.  People more likely to have angina ...\n",
      "\n",
      "[2] General Medicine\n",
      "    Keywords: \n",
      "    Preview: Transcription: REASON FOR CONSULTATION:,  Chest pain.,HISTORY OF PRESENT ILLNESS: , The patient is a 37-year-old gentleman admitted through emergency ...\n",
      "\n",
      "[3] Consult - History and Phy.\n",
      "    Keywords: \n",
      "    Preview: Transcription: REASON FOR CONSULTATION:,  Chest pain.,HISTORY OF PRESENT ILLNESS: , The patient is a 37-year-old gentleman admitted through emergency ...\n",
      "\n",
      "[4] Consult - History and Phy.\n",
      "    Keywords: \n",
      "    Preview: Transcription: CHIEF COMPLAINT (1/1):, This 62 year old female presents today for evaluation of angina.,Associated signs and symptoms: Associated sign...\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Question: How is a colonoscopy procedure performed?\n",
      "======================================================================\n",
      "\n",
      "Answer:\n",
      "A colonoscopy procedure involves several steps:\n",
      "\n",
      "1. Preparation: The patient's bowel is cleaned and prepared for the procedure.\n",
      "2. Positioning: The patient is placed in a left lateral position, which allows for optimal visualization of the colon.\n",
      "3. Inspection and digital exam: The perianal area and rectum are inspected and digitally examined to ensure there are no abnormalities.\n",
      "4. Colonoscope insertion: A video Olympus colonoscope is introduced into the rectum, allowing the physician to visualize the inside of the colon.\n",
      "5. Advancement: The instrument is advanced through the colon, including the sigmoid colon, which may be tortuous in this patient.\n",
      "6. Biopsy and culture: Random biopsies are taken from areas of concern, and cultures may be obtained as part of the procedure.\n",
      "\n",
      "It's essential to note that the procedure was explained to the patient, informed consent was obtained, and possible complications were discussed to ensure patient safety and understanding.\n",
      "\n",
      "Sources (4 documents):\n",
      "\n",
      "[1] Surgery\n",
      "    Keywords: surgery, colonoscopy with random biopsies, hepatic flexure, topical, culture, antibiotic, hepatic, f\n",
      "    Preview: Description: Colonoscopy with random biopsies and culture....\n",
      "\n",
      "[2] Gastroenterology\n",
      "    Keywords: gastroenterology, colonoscopy with random biopsies, hepatic flexure, topical, culture, antibiotic, h\n",
      "    Preview: Description: Colonoscopy with random biopsies and culture....\n",
      "\n",
      "[3] Surgery\n",
      "    Keywords: surgery, screening colonoscopy, colon cancer, colonoscopy, polyps, malignancy, sigmoid, rectum, cecu\n",
      "    Preview: Transcription: PROCEDURE: , Colonoscopy.,PREOPERATIVE DIAGNOSES:,  The patient is a 56-year-old female.  She was referred for a screening colonoscopy....\n",
      "\n",
      "[4] Gastroenterology\n",
      "    Keywords: gastroenterology, screening colonoscopy, colon cancer, colonoscopy, polyps, malignancy, sigmoid, rec\n",
      "    Preview: Transcription: PROCEDURE: , Colonoscopy.,PREOPERATIVE DIAGNOSES:,  The patient is a 56-year-old female.  She was referred for a screening colonoscopy....\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Question: How is a colonoscopy procedure performed?\n",
      "======================================================================\n",
      "\n",
      "Answer:\n",
      "A colonoscopy procedure involves several steps:\n",
      "\n",
      "1. Preparation: The patient's bowel is cleaned and prepared for the procedure.\n",
      "2. Positioning: The patient is placed in a left lateral position, which allows for optimal visualization of the colon.\n",
      "3. Inspection and digital exam: The perianal area and rectum are inspected and digitally examined to ensure there are no abnormalities.\n",
      "4. Colonoscope insertion: A video Olympus colonoscope is introduced into the rectum, allowing the physician to visualize the inside of the colon.\n",
      "5. Advancement: The instrument is advanced through the colon, including the sigmoid colon, which may be tortuous in this patient.\n",
      "6. Biopsy and culture: Random biopsies are taken from areas of concern, and cultures may be obtained as part of the procedure.\n",
      "\n",
      "It's essential to note that the procedure was explained to the patient, informed consent was obtained, and possible complications were discussed to ensure patient safety and understanding.\n",
      "\n",
      "Sources (4 documents):\n",
      "\n",
      "[1] Surgery\n",
      "    Keywords: surgery, colonoscopy with random biopsies, hepatic flexure, topical, culture, antibiotic, hepatic, f\n",
      "    Preview: Description: Colonoscopy with random biopsies and culture....\n",
      "\n",
      "[2] Gastroenterology\n",
      "    Keywords: gastroenterology, colonoscopy with random biopsies, hepatic flexure, topical, culture, antibiotic, h\n",
      "    Preview: Description: Colonoscopy with random biopsies and culture....\n",
      "\n",
      "[3] Surgery\n",
      "    Keywords: surgery, screening colonoscopy, colon cancer, colonoscopy, polyps, malignancy, sigmoid, rectum, cecu\n",
      "    Preview: Transcription: PROCEDURE: , Colonoscopy.,PREOPERATIVE DIAGNOSES:,  The patient is a 56-year-old female.  She was referred for a screening colonoscopy....\n",
      "\n",
      "[4] Gastroenterology\n",
      "    Keywords: gastroenterology, screening colonoscopy, colon cancer, colonoscopy, polyps, malignancy, sigmoid, rec\n",
      "    Preview: Transcription: PROCEDURE: , Colonoscopy.,PREOPERATIVE DIAGNOSES:,  The patient is a 56-year-old female.  She was referred for a screening colonoscopy....\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Question: What medications are used to treat hypertension?\n",
      "======================================================================\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, the medications listed for treating hypertension in this patient are:\n",
      "\n",
      "1. Aspirin\n",
      "2. Plavix (likely referring to Clopidogrel)\n",
      "3. Statins (type not specified)\n",
      "4. Beta blockers (type not specified, but likely Atenolol was discontinued and replaced with another beta blocker, possibly Metoprolol or Propranolol is not mentioned but other options like carvedilol are not listed either)\n",
      "5. ACE inhibitors (type not specified, but likely Lisinopril was discontinued and replaced with another ACE inhibitor, such as Captopril or Enalapril)\n",
      "\n",
      "Please note that the patient's current medication regimen may have changed since the last update, and it is essential to consult with the cardiologist, Dr., for the most up-to-date information on the patient's treatment plan.\n",
      "\n",
      "Sources (4 documents):\n",
      "\n",
      "[1] Surgery\n",
      "    Keywords: surgery, impella circulatory assist device, impella assist device, unstable angina, congestive heart\n",
      "    Preview: .  Aspirin, Plavix, statins, beta blockers, ACE inhibitors as tolerated.,2.  Hydration.,3.  The patient will be observed over night for any hemodynami...\n",
      "\n",
      "[2] Cardiovascular / Pulmonary\n",
      "    Keywords: cardiovascular / pulmonary, impella circulatory assist device, impella assist device, unstable angin\n",
      "    Preview: .  Aspirin, Plavix, statins, beta blockers, ACE inhibitors as tolerated.,2.  Hydration.,3.  The patient will be observed over night for any hemodynami...\n",
      "\n",
      "[3] General Medicine\n",
      "    Keywords: \n",
      "    Preview: .  Blood pressure improved, but postsurgery, the patient's blood pressure went up again to 180/100.  Currently, blood pressure is 158/100, goes up to ...\n",
      "\n",
      "[4] Consult - History and Phy.\n",
      "    Keywords: \n",
      "    Preview: .  Blood pressure improved, but postsurgery, the patient's blood pressure went up again to 180/100.  Currently, blood pressure is 158/100, goes up to ...\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Question: What medications are used to treat hypertension?\n",
      "======================================================================\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, the medications listed for treating hypertension in this patient are:\n",
      "\n",
      "1. Aspirin\n",
      "2. Plavix (likely referring to Clopidogrel)\n",
      "3. Statins (type not specified)\n",
      "4. Beta blockers (type not specified, but likely Atenolol was discontinued and replaced with another beta blocker, possibly Metoprolol or Propranolol is not mentioned but other options like carvedilol are not listed either)\n",
      "5. ACE inhibitors (type not specified, but likely Lisinopril was discontinued and replaced with another ACE inhibitor, such as Captopril or Enalapril)\n",
      "\n",
      "Please note that the patient's current medication regimen may have changed since the last update, and it is essential to consult with the cardiologist, Dr., for the most up-to-date information on the patient's treatment plan.\n",
      "\n",
      "Sources (4 documents):\n",
      "\n",
      "[1] Surgery\n",
      "    Keywords: surgery, impella circulatory assist device, impella assist device, unstable angina, congestive heart\n",
      "    Preview: .  Aspirin, Plavix, statins, beta blockers, ACE inhibitors as tolerated.,2.  Hydration.,3.  The patient will be observed over night for any hemodynami...\n",
      "\n",
      "[2] Cardiovascular / Pulmonary\n",
      "    Keywords: cardiovascular / pulmonary, impella circulatory assist device, impella assist device, unstable angin\n",
      "    Preview: .  Aspirin, Plavix, statins, beta blockers, ACE inhibitors as tolerated.,2.  Hydration.,3.  The patient will be observed over night for any hemodynami...\n",
      "\n",
      "[3] General Medicine\n",
      "    Keywords: \n",
      "    Preview: .  Blood pressure improved, but postsurgery, the patient's blood pressure went up again to 180/100.  Currently, blood pressure is 158/100, goes up to ...\n",
      "\n",
      "[4] Consult - History and Phy.\n",
      "    Keywords: \n",
      "    Preview: .  Blood pressure improved, but postsurgery, the patient's blood pressure went up again to 180/100.  Currently, blood pressure is 158/100, goes up to ...\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with sample medical questions\n",
    "sample_questions = [\n",
    "    \"What are common symptoms of coronary artery disease?\",\n",
    "    \"How is a colonoscopy procedure performed?\",\n",
    "    \"What medications are used to treat hypertension?\"\n",
    "]\n",
    "\n",
    "print(\"Testing RAG pipeline...\\n\")\n",
    "\n",
    "for question in sample_questions:\n",
    "    ask_medical_question(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f09c3",
   "metadata": {},
   "source": [
    "## Step 9: Interactive QA Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4a8f016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive Medical QA System\n",
      "Type your medical question below (or 'quit' to exit)\n",
      "\n",
      "Demo Mode: Running sample questions...\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Question: What is the procedure for a knee arthroscopy?\n",
      "======================================================================\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, I can provide a general overview of the procedure. Knee arthroscopy typically involves:\n",
      "\n",
      "1. Arthroscopic examination of the knee joint to visualize the interior structures.\n",
      "2. Removal of loose bodies or debris that may be causing symptoms.\n",
      "3. Medial femoral chondroplasty: a surgical procedure to smooth out the rough edges of the medial (inner) aspect of the femur (thigh bone).\n",
      "4. Meniscoplasty: a surgical procedure to repair or reconstruct damaged meniscal tissue in the knee joint.\n",
      "\n",
      "The specific steps and techniques used may vary depending on the individual patient's condition and the surgeon's preference.\n",
      "\n",
      "In this case, the procedures mentioned are specifically for an anterior cruciate ligament (ACL) reconstruction, which is often performed to stabilize the knee joint after a ligament injury.\n",
      "\n",
      "Sources (4 documents):\n",
      "\n",
      "[1] Surgery\n",
      "    Keywords: surgery, chondroplasty, knee, meniscus, patellofemoral, arthroscopy, portals, jointNOTE,: Thesetrans\n",
      "    Preview: Description: Arthroscopic procedure of the knee....\n",
      "\n",
      "[2] Orthopedic\n",
      "    Keywords: orthopedic, chondroplasty, knee, meniscus, patellofemoral, arthroscopy, portals, jointNOTE,: Thesetr\n",
      "    Preview: Description: Arthroscopic procedure of the knee....\n",
      "\n",
      "[3] Surgery\n",
      "    Keywords: surgery, femoral chondroplasty, intraarticular loose bodies, anterior cruciate ligament reconstructi\n",
      "    Preview: Description: Arthroscopy of the left knee was performed with the anterior cruciate ligament reconstruction.  Removal of loose bodies.  Medial femoral ...\n",
      "\n",
      "[4] Orthopedic\n",
      "    Keywords: orthopedic, femoral chondroplasty, intraarticular loose bodies, anterior cruciate ligament reconstru\n",
      "    Preview: Description: Arthroscopy of the left knee was performed with the anterior cruciate ligament reconstruction.  Removal of loose bodies.  Medial femoral ...\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Question: What is the procedure for a knee arthroscopy?\n",
      "======================================================================\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, I can provide a general overview of the procedure. Knee arthroscopy typically involves:\n",
      "\n",
      "1. Arthroscopic examination of the knee joint to visualize the interior structures.\n",
      "2. Removal of loose bodies or debris that may be causing symptoms.\n",
      "3. Medial femoral chondroplasty: a surgical procedure to smooth out the rough edges of the medial (inner) aspect of the femur (thigh bone).\n",
      "4. Meniscoplasty: a surgical procedure to repair or reconstruct damaged meniscal tissue in the knee joint.\n",
      "\n",
      "The specific steps and techniques used may vary depending on the individual patient's condition and the surgeon's preference.\n",
      "\n",
      "In this case, the procedures mentioned are specifically for an anterior cruciate ligament (ACL) reconstruction, which is often performed to stabilize the knee joint after a ligament injury.\n",
      "\n",
      "Sources (4 documents):\n",
      "\n",
      "[1] Surgery\n",
      "    Keywords: surgery, chondroplasty, knee, meniscus, patellofemoral, arthroscopy, portals, jointNOTE,: Thesetrans\n",
      "    Preview: Description: Arthroscopic procedure of the knee....\n",
      "\n",
      "[2] Orthopedic\n",
      "    Keywords: orthopedic, chondroplasty, knee, meniscus, patellofemoral, arthroscopy, portals, jointNOTE,: Thesetr\n",
      "    Preview: Description: Arthroscopic procedure of the knee....\n",
      "\n",
      "[3] Surgery\n",
      "    Keywords: surgery, femoral chondroplasty, intraarticular loose bodies, anterior cruciate ligament reconstructi\n",
      "    Preview: Description: Arthroscopy of the left knee was performed with the anterior cruciate ligament reconstruction.  Removal of loose bodies.  Medial femoral ...\n",
      "\n",
      "[4] Orthopedic\n",
      "    Keywords: orthopedic, femoral chondroplasty, intraarticular loose bodies, anterior cruciate ligament reconstru\n",
      "    Preview: Description: Arthroscopy of the left knee was performed with the anterior cruciate ligament reconstruction.  Removal of loose bodies.  Medial femoral ...\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Question: Describe the treatment for pneumonia\n",
      "======================================================================\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, I can provide general information about the treatment for pneumonia.\n",
      "\n",
      "Pneumonia is typically treated with antibiotics, which are prescribed by a healthcare provider based on the type of bacteria causing the infection. The choice of antibiotic depends on factors such as the severity of the illness, the patient's age and overall health, and any allergies or sensitivities they may have.\n",
      "\n",
      "In addition to antibiotics, other treatments for pneumonia may include:\n",
      "\n",
      "* Rest and hydration\n",
      "* Oxygen therapy to help increase oxygen levels in the blood\n",
      "* Pain management with medications such as acetaminophen or ibuprofen\n",
      "* Antipyretics (fever-reducing medications) if fever is present\n",
      "\n",
      "It's also important to note that patients with severe pneumonia, such as those requiring ICU admission, may require more aggressive treatment, including mechanical ventilation and other supportive care measures.\n",
      "\n",
      "However, I would like to clarify that the specific treatment plan for this patient should be determined by a healthcare provider, taking into account the patient's individual needs and medical history.\n",
      "\n",
      "Sources (4 documents):\n",
      "\n",
      "[1] SOAP / Chart / Progress Notes\n",
      "    Keywords: soap / chart / progress notes, shortness of breath, pulmonary medicine, bipolar disorder, icuNOTE\n",
      "    Preview: Description: The patient was admitted approximately 3 days ago with increasing shortness of breath secondary to pneumonia.  Pulmonary Medicine Associa...\n",
      "\n",
      "[2] General Medicine\n",
      "    Keywords: general medicine, shortness of breath, pulmonary medicine, bipolar disorder, icuNOTE,: Thesetranscri\n",
      "    Preview: Description: The patient was admitted approximately 3 days ago with increasing shortness of breath secondary to pneumonia.  Pulmonary Medicine Associa...\n",
      "\n",
      "[3] Cardiovascular / Pulmonary\n",
      "    Keywords: cardiovascular / pulmonary, shortness of breath, pulmonary medicine, bipolar disorder, icuNOTE\n",
      "    Preview: Description: The patient was admitted approximately 3 days ago with increasing shortness of breath secondary to pneumonia.  Pulmonary Medicine Associa...\n",
      "\n",
      "[4] SOAP / Chart / Progress Notes\n",
      "    Keywords: soap / chart / progress notes, antibiotics, febrile seizure, temperature, blood count, white count, \n",
      "    Preview: Description: The patient has recently had an admission for pneumonia with positive blood count.  She returned after vomiting and a probable seizure....\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "You can now ask your own questions!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Question: Describe the treatment for pneumonia\n",
      "======================================================================\n",
      "\n",
      "Answer:\n",
      "Based on the provided context, I can provide general information about the treatment for pneumonia.\n",
      "\n",
      "Pneumonia is typically treated with antibiotics, which are prescribed by a healthcare provider based on the type of bacteria causing the infection. The choice of antibiotic depends on factors such as the severity of the illness, the patient's age and overall health, and any allergies or sensitivities they may have.\n",
      "\n",
      "In addition to antibiotics, other treatments for pneumonia may include:\n",
      "\n",
      "* Rest and hydration\n",
      "* Oxygen therapy to help increase oxygen levels in the blood\n",
      "* Pain management with medications such as acetaminophen or ibuprofen\n",
      "* Antipyretics (fever-reducing medications) if fever is present\n",
      "\n",
      "It's also important to note that patients with severe pneumonia, such as those requiring ICU admission, may require more aggressive treatment, including mechanical ventilation and other supportive care measures.\n",
      "\n",
      "However, I would like to clarify that the specific treatment plan for this patient should be determined by a healthcare provider, taking into account the patient's individual needs and medical history.\n",
      "\n",
      "Sources (4 documents):\n",
      "\n",
      "[1] SOAP / Chart / Progress Notes\n",
      "    Keywords: soap / chart / progress notes, shortness of breath, pulmonary medicine, bipolar disorder, icuNOTE\n",
      "    Preview: Description: The patient was admitted approximately 3 days ago with increasing shortness of breath secondary to pneumonia.  Pulmonary Medicine Associa...\n",
      "\n",
      "[2] General Medicine\n",
      "    Keywords: general medicine, shortness of breath, pulmonary medicine, bipolar disorder, icuNOTE,: Thesetranscri\n",
      "    Preview: Description: The patient was admitted approximately 3 days ago with increasing shortness of breath secondary to pneumonia.  Pulmonary Medicine Associa...\n",
      "\n",
      "[3] Cardiovascular / Pulmonary\n",
      "    Keywords: cardiovascular / pulmonary, shortness of breath, pulmonary medicine, bipolar disorder, icuNOTE\n",
      "    Preview: Description: The patient was admitted approximately 3 days ago with increasing shortness of breath secondary to pneumonia.  Pulmonary Medicine Associa...\n",
      "\n",
      "[4] SOAP / Chart / Progress Notes\n",
      "    Keywords: soap / chart / progress notes, antibiotics, febrile seizure, temperature, blood count, white count, \n",
      "    Preview: Description: The patient has recently had an admission for pneumonia with positive blood count.  She returned after vomiting and a probable seizure....\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "You can now ask your own questions!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Interactive question answering\n",
    "print(\"Interactive Medical QA System\")\n",
    "print(\"Type your medical question below (or 'quit' to exit)\\n\")\n",
    "\n",
    "# Interactive mode for local environment\n",
    "def run_interactive_qa():\n",
    "    while True:\n",
    "        user_question = input(\"\\nYour question (or 'quit' to exit): \")\n",
    "        if user_question.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"\\nThank you for using the Medical QA System!\")\n",
    "            break\n",
    "        if user_question.strip():\n",
    "            ask_medical_question(user_question)\n",
    "        else:\n",
    "            print(\"Please enter a valid question.\")\n",
    "\n",
    "# Demo questions\n",
    "demo_questions = [\n",
    "    \"What is the procedure for a knee arthroscopy?\",\n",
    "    \"Describe the treatment for pneumonia\"\n",
    "]\n",
    "\n",
    "print(\"Demo Mode: Running sample questions...\\n\")\n",
    "for q in demo_questions:\n",
    "    ask_medical_question(q)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"You can now ask your own questions!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Uncomment the line below to enable interactive mode\n",
    "# run_interactive_qa()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38cbb6",
   "metadata": {},
   "source": [
    "## Step 10: Evaluation on 30+ Medical Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f10c8447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 33 evaluation queries\n",
      "Queries cover: Cardiology, Gastroenterology, Orthopedics, Neurology, Pulmonology, Dermatology, Endocrinology, Surgery, Urology, Ophthalmology\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive evaluation questions covering different medical specialties\n",
    "evaluation_queries = [\n",
    "    # Cardiology\n",
    "    \"What are the symptoms of heart failure?\",\n",
    "    \"How is atrial fibrillation treated?\",\n",
    "    \"What tests are done for chest pain evaluation?\",\n",
    "    \n",
    "    # Gastroenterology\n",
    "    \"What is the procedure for an upper endoscopy?\",\n",
    "    \"How is Crohn's disease diagnosed?\",\n",
    "    \"What are the symptoms of GERD?\",\n",
    "    \n",
    "    # Orthopedics\n",
    "    \"What is the recovery time for hip replacement?\",\n",
    "    \"How is a rotator cuff tear treated?\",\n",
    "    \"What are common knee injuries?\",\n",
    "    \n",
    "    # Neurology\n",
    "    \"What are the warning signs of a stroke?\",\n",
    "    \"How is migraine headache managed?\",\n",
    "    \"What tests diagnose epilepsy?\",\n",
    "    \n",
    "    # Pulmonology\n",
    "    \"What is the treatment for asthma?\",\n",
    "    \"How is COPD diagnosed?\",\n",
    "    \"What are symptoms of pulmonary embolism?\",\n",
    "    \n",
    "    # Dermatology\n",
    "    \"How is melanoma detected?\",\n",
    "    \"What treatments are available for eczema?\",\n",
    "    \"What causes psoriasis?\",\n",
    "    \n",
    "    # Endocrinology\n",
    "    \"What are the symptoms of hypothyroidism?\",\n",
    "    \"How is diabetes mellitus managed?\",\n",
    "    \"What tests check thyroid function?\",\n",
    "    \n",
    "    # General Surgery\n",
    "    \"What is involved in appendectomy surgery?\",\n",
    "    \"How is a hernia repaired?\",\n",
    "    \"What is laparoscopic surgery?\",\n",
    "    \n",
    "    # Urology\n",
    "    \"What are the symptoms of kidney stones?\",\n",
    "    \"How is benign prostatic hyperplasia treated?\",\n",
    "    \"What procedures diagnose bladder problems?\",\n",
    "    \n",
    "    # Ophthalmology\n",
    "    \"What is cataract surgery?\",\n",
    "    \"How is glaucoma treated?\",\n",
    "    \"What causes macular degeneration?\",\n",
    "    \n",
    "    # General Medicine\n",
    "    \"What medications treat high blood pressure?\",\n",
    "    \"How is anemia diagnosed?\",\n",
    "    \"What are symptoms of dehydration?\"\n",
    "]\n",
    "\n",
    "print(f\"Prepared {len(evaluation_queries)} evaluation queries\")\n",
    "print(\"Queries cover: Cardiology, Gastroenterology, Orthopedics, Neurology, Pulmonology, Dermatology, Endocrinology, Surgery, Urology, Ophthalmology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4ded868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on 33 queries...\n",
      "\n",
      "[1/33] What are the symptoms of heart failure?...\n",
      "[2/33] How is atrial fibrillation treated?...\n",
      "[2/33] How is atrial fibrillation treated?...\n",
      "[3/33] What tests are done for chest pain evaluation?...\n",
      "[3/33] What tests are done for chest pain evaluation?...\n",
      "[4/33] What is the procedure for an upper endoscopy?...\n",
      "[4/33] What is the procedure for an upper endoscopy?...\n",
      "[5/33] How is Crohn's disease diagnosed?...\n",
      "[5/33] How is Crohn's disease diagnosed?...\n",
      "[6/33] What are the symptoms of GERD?...\n",
      "[6/33] What are the symptoms of GERD?...\n",
      "[7/33] What is the recovery time for hip replacement?...\n",
      "[7/33] What is the recovery time for hip replacement?...\n",
      "[8/33] How is a rotator cuff tear treated?...\n",
      "[8/33] How is a rotator cuff tear treated?...\n",
      "[9/33] What are common knee injuries?...\n",
      "[9/33] What are common knee injuries?...\n",
      "[10/33] What are the warning signs of a stroke?...\n",
      "[10/33] What are the warning signs of a stroke?...\n",
      "[11/33] How is migraine headache managed?...\n",
      "[11/33] How is migraine headache managed?...\n",
      "[12/33] What tests diagnose epilepsy?...\n",
      "[12/33] What tests diagnose epilepsy?...\n",
      "[13/33] What is the treatment for asthma?...\n",
      "[13/33] What is the treatment for asthma?...\n",
      "[14/33] How is COPD diagnosed?...\n",
      "[14/33] How is COPD diagnosed?...\n",
      "[15/33] What are symptoms of pulmonary embolism?...\n",
      "[15/33] What are symptoms of pulmonary embolism?...\n",
      "[16/33] How is melanoma detected?...\n",
      "[16/33] How is melanoma detected?...\n",
      "[17/33] What treatments are available for eczema?...\n",
      "[17/33] What treatments are available for eczema?...\n",
      "[18/33] What causes psoriasis?...\n",
      "[18/33] What causes psoriasis?...\n",
      "[19/33] What are the symptoms of hypothyroidism?...\n",
      "[19/33] What are the symptoms of hypothyroidism?...\n",
      "[20/33] How is diabetes mellitus managed?...\n",
      "[20/33] How is diabetes mellitus managed?...\n",
      "[21/33] What tests check thyroid function?...\n",
      "[21/33] What tests check thyroid function?...\n",
      "[22/33] What is involved in appendectomy surgery?...\n",
      "[22/33] What is involved in appendectomy surgery?...\n",
      "[23/33] How is a hernia repaired?...\n",
      "[23/33] How is a hernia repaired?...\n",
      "[24/33] What is laparoscopic surgery?...\n",
      "[24/33] What is laparoscopic surgery?...\n",
      "[25/33] What are the symptoms of kidney stones?...\n",
      "[25/33] What are the symptoms of kidney stones?...\n",
      "[26/33] How is benign prostatic hyperplasia treated?...\n",
      "[26/33] How is benign prostatic hyperplasia treated?...\n",
      "[27/33] What procedures diagnose bladder problems?...\n",
      "[27/33] What procedures diagnose bladder problems?...\n",
      "[28/33] What is cataract surgery?...\n",
      "[28/33] What is cataract surgery?...\n",
      "[29/33] How is glaucoma treated?...\n",
      "[29/33] How is glaucoma treated?...\n",
      "[30/33] What causes macular degeneration?...\n",
      "[30/33] What causes macular degeneration?...\n",
      "[31/33] What medications treat high blood pressure?...\n",
      "[31/33] What medications treat high blood pressure?...\n",
      "[32/33] How is anemia diagnosed?...\n",
      "[32/33] How is anemia diagnosed?...\n",
      "[33/33] What are symptoms of dehydration?...\n",
      "[33/33] What are symptoms of dehydration?...\n",
      "\n",
      "Evaluation complete: 33 queries processed\n",
      "\n",
      "Evaluation complete: 33 queries processed\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation on all queries\n",
    "print(f\"Running evaluation on {len(evaluation_queries)} queries...\\n\")\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for i, query in enumerate(evaluation_queries, 1):\n",
    "    print(f\"[{i}/{len(evaluation_queries)}] {query[:50]}...\")\n",
    "    \n",
    "    try:\n",
    "        result = qa_chain.invoke({\"query\": query})\n",
    "        \n",
    "        eval_record = {\n",
    "            'query_id': i,\n",
    "            'question': query,\n",
    "            'answer': result['result'],\n",
    "            'num_sources': len(result['source_documents']),\n",
    "            'source_specialties': [doc.metadata.get('medical_specialty', 'Unknown') \n",
    "                                   for doc in result['source_documents']],\n",
    "            'answer_length': len(result['result']),\n",
    "            'has_answer': len(result['result']) > 50\n",
    "        }\n",
    "        \n",
    "        evaluation_results.append(eval_record)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {str(e)}\")\n",
    "        \n",
    "        evaluation_results.append({\n",
    "            'query_id': i,\n",
    "            'question': query,\n",
    "            'answer': f\"Error: {str(e)}\",\n",
    "            'num_sources': 0,\n",
    "            'source_specialties': [],\n",
    "            'answer_length': 0,\n",
    "            'has_answer': False\n",
    "        })\n",
    "\n",
    "print(f\"\\nEvaluation complete: {len(evaluation_results)} queries processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a742c5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Summary Statistics:\n",
      "==================================================\n",
      "Total queries evaluated: 33\n",
      "Successful answers: 33\n",
      "Average answer length: 842 characters\n",
      "Average sources per query: 4.0\n",
      "\n",
      "Answer length distribution:\n",
      "count      33.000000\n",
      "mean      842.333333\n",
      "std       378.570970\n",
      "min       285.000000\n",
      "25%       488.000000\n",
      "50%       882.000000\n",
      "75%      1147.000000\n",
      "max      1636.000000\n",
      "Name: answer_length, dtype: float64\n",
      "\n",
      "==================================================\n",
      "Sample Evaluation Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>num_sources</th>\n",
       "      <th>source_specialties</th>\n",
       "      <th>answer_length</th>\n",
       "      <th>has_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What are the symptoms of heart failure?</td>\n",
       "      <td>I don't have enough information in the provide...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Consult - History and Phy., Cardiovascular / ...</td>\n",
       "      <td>753</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How is atrial fibrillation treated?</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Consult - History and Phy., Cardiovascular / ...</td>\n",
       "      <td>1567</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>What tests are done for chest pain evaluation?</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Cardiovascular / Pulmonary, Consult - History...</td>\n",
       "      <td>463</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the procedure for an upper endoscopy?</td>\n",
       "      <td>Based on the provided context from medical rec...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Surgery, Gastroenterology, Surgery, Gastroent...</td>\n",
       "      <td>999</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How is Crohn's disease diagnosed?</td>\n",
       "      <td>Crohn's disease is typically diagnosed based o...</td>\n",
       "      <td>4</td>\n",
       "      <td>[General Medicine, Consult - History and Phy.,...</td>\n",
       "      <td>1223</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>What are the symptoms of GERD?</td>\n",
       "      <td>I don't have enough information in the provide...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Emergency Room Reports, Cardiovascular / Pulm...</td>\n",
       "      <td>684</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>What is the recovery time for hip replacement?</td>\n",
       "      <td>I don't have enough information in the provide...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Surgery, Orthopedic, Physical Medicine - Reha...</td>\n",
       "      <td>925</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>How is a rotator cuff tear treated?</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Orthopedic, Surgery, Radiology, Orthopedic]</td>\n",
       "      <td>1263</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>What are common knee injuries?</td>\n",
       "      <td>I don't have enough information in the provide...</td>\n",
       "      <td>4</td>\n",
       "      <td>[IME-QME-Work Comp etc., Consult - History and...</td>\n",
       "      <td>296</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>What are the warning signs of a stroke?</td>\n",
       "      <td>According to the provided context, the warning...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Consult - History and Phy., General Medicine,...</td>\n",
       "      <td>553</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                        question  \\\n",
       "0         1         What are the symptoms of heart failure?   \n",
       "1         2             How is atrial fibrillation treated?   \n",
       "2         3  What tests are done for chest pain evaluation?   \n",
       "3         4   What is the procedure for an upper endoscopy?   \n",
       "4         5               How is Crohn's disease diagnosed?   \n",
       "5         6                  What are the symptoms of GERD?   \n",
       "6         7  What is the recovery time for hip replacement?   \n",
       "7         8             How is a rotator cuff tear treated?   \n",
       "8         9                  What are common knee injuries?   \n",
       "9        10         What are the warning signs of a stroke?   \n",
       "\n",
       "                                              answer  num_sources  \\\n",
       "0  I don't have enough information in the provide...            4   \n",
       "1  Based on the provided context, it appears that...            4   \n",
       "2  Based on the provided context, it appears that...            4   \n",
       "3  Based on the provided context from medical rec...            4   \n",
       "4  Crohn's disease is typically diagnosed based o...            4   \n",
       "5  I don't have enough information in the provide...            4   \n",
       "6  I don't have enough information in the provide...            4   \n",
       "7  Based on the provided context, it appears that...            4   \n",
       "8  I don't have enough information in the provide...            4   \n",
       "9  According to the provided context, the warning...            4   \n",
       "\n",
       "                                  source_specialties  answer_length  \\\n",
       "0  [Consult - History and Phy., Cardiovascular / ...            753   \n",
       "1  [Consult - History and Phy., Cardiovascular / ...           1567   \n",
       "2  [Cardiovascular / Pulmonary, Consult - History...            463   \n",
       "3  [Surgery, Gastroenterology, Surgery, Gastroent...            999   \n",
       "4  [General Medicine, Consult - History and Phy.,...           1223   \n",
       "5  [Emergency Room Reports, Cardiovascular / Pulm...            684   \n",
       "6  [Surgery, Orthopedic, Physical Medicine - Reha...            925   \n",
       "7       [Orthopedic, Surgery, Radiology, Orthopedic]           1263   \n",
       "8  [IME-QME-Work Comp etc., Consult - History and...            296   \n",
       "9  [Consult - History and Phy., General Medicine,...            553   \n",
       "\n",
       "   has_answer  \n",
       "0        True  \n",
       "1        True  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  \n",
       "5        True  \n",
       "6        True  \n",
       "7        True  \n",
       "8        True  \n",
       "9        True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create evaluation DataFrame\n",
    "eval_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "print(\"Evaluation Summary Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total queries evaluated: {len(eval_df)}\")\n",
    "print(f\"Successful answers: {eval_df['has_answer'].sum()}\")\n",
    "print(f\"Average answer length: {eval_df['answer_length'].mean():.0f} characters\")\n",
    "print(f\"Average sources per query: {eval_df['num_sources'].mean():.1f}\")\n",
    "print(f\"\\nAnswer length distribution:\")\n",
    "print(eval_df['answer_length'].describe())\n",
    "\n",
    "# Display first few results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Sample Evaluation Results:\")\n",
    "eval_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "919b68ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Results (First 5 Queries):\n",
      "\n",
      "======================================================================\n",
      "[1] What are the symptoms of heart failure?\n",
      "======================================================================\n",
      "Answer: I don't have enough information in the provided context to answer this question accurately. The context only mentions that the patient has dilated cardiomyopathy and presents with a chief complaint of...\n",
      "Sources: 4\n",
      "Specialties: Cardiovascular / Pulmonary, Consult - History and Phy.\n",
      "\n",
      "======================================================================\n",
      "[2] How is atrial fibrillation treated?\n",
      "======================================================================\n",
      "Answer: Based on the provided context, it appears that the patient has been diagnosed with atrial fibrillation (AFib) and has undergone unsuccessful direct current cardioversion attempts. The medical records ...\n",
      "Sources: 4\n",
      "Specialties: Cardiovascular / Pulmonary, Consult - History and Phy., Surgery\n",
      "\n",
      "======================================================================\n",
      "[3] What tests are done for chest pain evaluation?\n",
      "======================================================================\n",
      "Answer: Based on the provided context, it appears that the following tests are typically performed to evaluate chest pain:\n",
      "\n",
      "1. Exercise stress test with nuclear scan (as mentioned in the first description)\n",
      "2....\n",
      "Sources: 4\n",
      "Specialties: Cardiovascular / Pulmonary, Consult - History and Phy.\n",
      "\n",
      "======================================================================\n",
      "[4] What is the procedure for an upper endoscopy?\n",
      "======================================================================\n",
      "Answer: Based on the provided context from medical records, it appears that an upper endoscopy involves the insertion of a flexible tube with a camera and light (endoscope) into the mouth to visually examine ...\n",
      "Sources: 4\n",
      "Specialties: Gastroenterology, Surgery\n",
      "\n",
      "======================================================================\n",
      "[5] How is Crohn's disease diagnosed?\n",
      "======================================================================\n",
      "Answer: Crohn's disease is typically diagnosed based on a combination of clinical presentation, laboratory findings, and endoscopic examination. The diagnosis can be confirmed by:\n",
      "\n",
      "1. Endoscopy with biopsy: B...\n",
      "Sources: 4\n",
      "Specialties: Surgery, General Medicine, Consult - History and Phy., Gastroenterology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display detailed results for first 5 queries\n",
    "print(\"\\nSample Results (First 5 Queries):\\n\")\n",
    "\n",
    "for i in range(min(5, len(evaluation_results))):\n",
    "    result = evaluation_results[i]\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"[{result['query_id']}] {result['question']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Answer: {result['answer'][:200]}...\")  # Truncate for readability\n",
    "    print(f\"Sources: {result['num_sources']}\")\n",
    "    print(f\"Specialties: {', '.join(set(result['source_specialties']))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "361d43e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved:\n",
      "  - output\\evaluation_results.csv\n",
      "  - output\\evaluation_results.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save evaluation results\n",
    "eval_df.to_csv(output_dir / 'evaluation_results.csv', index=False)\n",
    "\n",
    "with open(output_dir / 'evaluation_results.pkl', 'wb') as f:\n",
    "    pickle.dump(evaluation_results, f)\n",
    "\n",
    "print(f\"Results saved:\")\n",
    "print(f\"  - {output_dir / 'evaluation_results.csv'}\")\n",
    "print(f\"  - {output_dir / 'evaluation_results.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5829cffc",
   "metadata": {},
   "source": [
    "## Step 11: Generate Evaluation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a8ad4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation report generated!\n",
      "Saved to: output\\evaluation_report.md\n",
      "\n",
      "======================================================================\n",
      "# Medical RAG QA System - Evaluation Report\n",
      "\n",
      "## System Configuration\n",
      "- **Dataset**: Medical Transcriptions (Kaggle)\n",
      "- **Records Processed**: 4943\n",
      "- **Total Chunks**: 25173\n",
      "- **Embedding Model**: all-MiniLM-L6-v2\n",
      "- **Vector Store**: FAISS\n",
      "- **LLM**: llama3.2\n",
      "- **Chunk Size**: 1000 characters\n",
      "- **Chunk Overlap**: 200 characters\n",
      "- **Retrieval Count**: 4 documents\n",
      "\n",
      "## Evaluation Results\n",
      "\n",
      "### Overall Statistics\n",
      "- **Total Queries**: 33\n",
      "- **Successful Answers**: 33\n",
      "- **Success Rate**: 100.0%\n",
      "- **Average Answer Length**: 842 characters\n",
      "- **Average Sources per Query**: 4.0\n",
      "\n",
      "### Answer Length Distribution\n",
      "- **Minimum**: 285 characters\n",
      "- **Maximum**: 1636 characters\n",
      "- **Median**: 882 characters\n",
      "- **Std Dev**: 379 characters\n",
      "\n",
      "### Medical Specialties Covered\n",
      "The evaluation covered queries across multiple medical specialties including:\n",
      "- Cardiology\n",
      "- Gastroenterology\n",
      "- Orthopedics\n",
      "- Neurology\n",
      "- Pulmonology\n",
      "- Dermatology\n",
      "- Endocrinology\n",
      "- General Surgery\n",
      "- Urology\n",
      "- Ophthalmology\n",
      "\n",
      "## Sample Outputs\n",
      "\n",
      "### Example 1\n",
      "**Question**: What are the symptoms of heart failure?\n",
      "\n",
      "**Answer**: I don't have enough information in the provided context to answer this question accurately. The context only mentions that the patient has dilated cardiomyopathy and presents with a chief complaint of heart failure, but it does not provide a comprehensive list of symptoms associated with heart failure. According to the American Heart Association, common symptoms of heart failure include:\n",
      "\n",
      "* Shortness of breath (dyspnea) at rest or exertion\n",
      "* Fatigue\n",
      "* Swelling in the legs, ankles, and feet (edema)\n",
      "* Rapid or irregular heartbeat (arrhythmia)\n",
      "* Coughing up pink, frothy mucus (pleural effusion)\n",
      "* Weight gain\n",
      "* Loss of appetite\n",
      "\n",
      "However, without more specific information about the patient's symptoms, it is difficult to provide a definitive answer.\n",
      "\n",
      "**Sources**: 4 documents from Cardiovascular / Pulmonary, Consult - History and Phy.\n",
      "\n",
      "---\n",
      "\n",
      "### Example 2\n",
      "**Question**: How is atrial fibrillation treated?\n",
      "\n",
      "**Answer**: Based on the provided context, it appears that the patient has been diagnosed with atrial fibrillation (AFib) and has undergone unsuccessful direct current cardioversion attempts. The medical records do not provide information on alternative treatment options or management strategies for AFib.\n",
      "\n",
      "However, I can suggest some general treatment approaches for atrial fibrillation:\n",
      "\n",
      "1. Rate control: Medications such as beta-blockers, non-dihydropyridine calcium channel blockers (e.g., verapamil), and digoxin are often used to control the ventricular rate in patients with AFib.\n",
      "2. Rhythm control: Anticoagulation therapy is typically used to prevent stroke in patients with AFib, and rhythm control medications such as flecainide or propafenone may be prescribed to attempt to restore a normal sinus rhythm.\n",
      "3. Cardioversion: As the patient has already undergone unsuccessful direct current cardioversion attempts, alternative methods such as electrical cardioversion or pharmacological cardioversion (e.g., using amiodarone) may be considered.\n",
      "\n",
      "It is essential to note that each patient's treatment plan should be individualized based on their specific medical history, symptoms, and comorbidities. A cardiologist or other qualified healthcare professional should be consulted for personalized guidance on managing atrial fibrillation.\n",
      "\n",
      "In this case, since the context does not provide information on the patient's current treatment plan or management strategy, I would recommend consulting with a cardiologist to determine the best course of action for this patient.\n",
      "\n",
      "**Sources**: 4 documents from Cardiovascular / Pulmonary, Consult - History and Phy., Surgery\n",
      "\n",
      "---\n",
      "\n",
      "### Example 3\n",
      "**Question**: What tests are done for chest pain evaluation?\n",
      "\n",
      "**Answer**: Based on the provided context, it appears that the following tests are typically performed to evaluate chest pain:\n",
      "\n",
      "1. Exercise stress test with nuclear scan (as mentioned in the first description)\n",
      "2. Electrocardiogram (EKG) - as indicated in the descriptions and findings\n",
      "3. Continuous hemodynamic monitoring - as described in the transcription\n",
      "\n",
      "These tests are likely used to assess cardiovascular function, particularly in cases of exercise-induced chest pain.\n",
      "\n",
      "**Sources**: 4 documents from Cardiovascular / Pulmonary, Consult - History and Phy.\n",
      "\n",
      "---\n",
      "\n",
      "## Key Findings\n",
      "\n",
      "1. **Retrieval Quality**: The system successfully retrieves relevant medical context from the transcription database.\n",
      "\n",
      "2. **Answer Accuracy**: Answers are grounded in the provided context and include appropriate medical terminology.\n",
      "\n",
      "3. **Citation Awareness**: The system provides source attribution through metadata (specialty, keywords).\n",
      "\n",
      "4. **Safety**: The system appropriately defers when insufficient context is available.\n",
      "\n",
      "5. **No Training Required**: RAG uses pre-trained models (embeddings + LLM) and only creates a searchable vector index.\n",
      "\n",
      "## Files Generated\n",
      "- `preprocessed_chunks.pkl`: Preprocessed document chunks with metadata\n",
      "- `faiss_medical_index/`: FAISS vector store (no model training, just document indexing)\n",
      "- `rag_config.pkl`: RAG pipeline configuration\n",
      "- `evaluation_results.csv`: Detailed evaluation results\n",
      "- `evaluation_results.pkl`: Evaluation results (pickle format)\n",
      "- `evaluation_report.md`: This report\n",
      "\n",
      "## How Local Deployment Works\n",
      "1. **Load FAISS vector index** from disk (pre-computed embeddings)\n",
      "2. **User asks question** → Search FAISS for relevant chunks locally\n",
      "3. **Retrieved chunks sent** to local Ollama LLM (running on same machine)\n",
      "4. **Llama 3.2 generates** answer based on the context\n",
      "5. **Everything runs offline** - no internet required after setup!\n",
      "\n",
      "## Next Steps for Deployment\n",
      "1. Ensure Ollama is installed and running\n",
      "2. Load the FAISS index and model\n",
      "3. Run locally as Python script or Streamlit app\n",
      "4. No API keys needed - everything is local!\n",
      "5. Deploy on your own server or run on desktop\n",
      "\n",
      "---\n",
      "*Report generated on: 2025-11-27 00:33:16*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate evaluation report\n",
    "report = f\"\"\"# Medical RAG QA System - Evaluation Report\n",
    "\n",
    "## System Configuration\n",
    "- **Dataset**: Medical Transcriptions (Kaggle)\n",
    "- **Records Processed**: {len(df_subset)}\n",
    "- **Total Chunks**: {len(chunks)}\n",
    "- **Embedding Model**: {EMBEDDING_MODEL}\n",
    "- **Vector Store**: FAISS\n",
    "- **LLM**: {LLM_MODEL}\n",
    "- **Chunk Size**: 1000 characters\n",
    "- **Chunk Overlap**: 200 characters\n",
    "- **Retrieval Count**: 4 documents\n",
    "\n",
    "## Evaluation Results\n",
    "\n",
    "### Overall Statistics\n",
    "- **Total Queries**: {len(eval_df)}\n",
    "- **Successful Answers**: {eval_df['has_answer'].sum()}\n",
    "- **Success Rate**: {(eval_df['has_answer'].sum() / len(eval_df) * 100):.1f}%\n",
    "- **Average Answer Length**: {eval_df['answer_length'].mean():.0f} characters\n",
    "- **Average Sources per Query**: {eval_df['num_sources'].mean():.1f}\n",
    "\n",
    "### Answer Length Distribution\n",
    "- **Minimum**: {eval_df['answer_length'].min()} characters\n",
    "- **Maximum**: {eval_df['answer_length'].max()} characters\n",
    "- **Median**: {eval_df['answer_length'].median():.0f} characters\n",
    "- **Std Dev**: {eval_df['answer_length'].std():.0f} characters\n",
    "\n",
    "### Medical Specialties Covered\n",
    "The evaluation covered queries across multiple medical specialties including:\n",
    "- Cardiology\n",
    "- Gastroenterology\n",
    "- Orthopedics\n",
    "- Neurology\n",
    "- Pulmonology\n",
    "- Dermatology\n",
    "- Endocrinology\n",
    "- General Surgery\n",
    "- Urology\n",
    "- Ophthalmology\n",
    "\n",
    "## Sample Outputs\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Add sample Q&A pairs to report\n",
    "for i in range(min(3, len(evaluation_results))):\n",
    "    result = evaluation_results[i]\n",
    "    report += f\"\"\"### Example {i+1}\n",
    "**Question**: {result['question']}\n",
    "\n",
    "**Answer**: {result['answer']}\n",
    "\n",
    "**Sources**: {result['num_sources']} documents from {', '.join(set(result['source_specialties']))}\n",
    "\n",
    "---\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "report += f\"\"\"## Key Findings\n",
    "\n",
    "1. **Retrieval Quality**: The system successfully retrieves relevant medical context from the transcription database.\n",
    "\n",
    "2. **Answer Accuracy**: Answers are grounded in the provided context and include appropriate medical terminology.\n",
    "\n",
    "3. **Citation Awareness**: The system provides source attribution through metadata (specialty, keywords).\n",
    "\n",
    "4. **Safety**: The system appropriately defers when insufficient context is available.\n",
    "\n",
    "5. **No Training Required**: RAG uses pre-trained models (embeddings + LLM) and only creates a searchable vector index.\n",
    "\n",
    "## Files Generated\n",
    "- `preprocessed_chunks.pkl`: Preprocessed document chunks with metadata\n",
    "- `faiss_medical_index/`: FAISS vector store (no model training, just document indexing)\n",
    "- `rag_config.pkl`: RAG pipeline configuration\n",
    "- `evaluation_results.csv`: Detailed evaluation results\n",
    "- `evaluation_results.pkl`: Evaluation results (pickle format)\n",
    "- `evaluation_report.md`: This report\n",
    "\n",
    "## How Local Deployment Works\n",
    "1. **Load FAISS vector index** from disk (pre-computed embeddings)\n",
    "2. **User asks question** → Search FAISS for relevant chunks locally\n",
    "3. **Retrieved chunks sent** to local Ollama LLM (running on same machine)\n",
    "4. **Llama 3.2 generates** answer based on the context\n",
    "5. **Everything runs offline** - no internet required after setup!\n",
    "\n",
    "## Next Steps for Deployment\n",
    "1. Ensure Ollama is installed and running\n",
    "2. Load the FAISS index and model\n",
    "3. Run locally as Python script or Streamlit app\n",
    "4. No API keys needed - everything is local!\n",
    "5. Deploy on your own server or run on desktop\n",
    "\n",
    "---\n",
    "*Report generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}*\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "with open(output_dir / 'evaluation_report.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"Evaluation report generated!\")\n",
    "print(f\"Saved to: {output_dir / 'evaluation_report.md'}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
